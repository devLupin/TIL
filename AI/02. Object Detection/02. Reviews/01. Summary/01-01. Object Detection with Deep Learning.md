# **Object Detection with Deep Learning**

<hr>

```
[1] : Zhao, Z.-Q. Author, Zheng, P., Xu, S.-T.(2019). Object Detection with Deep Learning: A Review. IEEE Transactions on Neural Networks and Learning Systems, 30(11),8627998, pp. 3212-3232.
```



## Object Detection

<hr>

- Object Detection : 주어진 이미지에서 객체가 어디에 있는지(object localization), 각 객체가 속한 범주(object classification) 결정 
  1. Informative region selection
     - 이미지의 어느 위치에나 다른 물체가 나타날 수 있고 가로 세로 비율이나 크기가 다를 수 있음.
     - 멀티 스케일 슬라이딩 윈도우로 전체 이미지 스캔하
     - 후보 창(candidate windows)이 많기 때문에 계산 비용이 많이 들고 중복 창(redundant windows)이 많이 생성됨.
  2. Feature extraction
     - 대표적 특징 : Scale-invariant feature transform(SIFT) , histograms of oriented gradients (HOG) [20] , Haar-like
  3. Classification
     - 대상 객체를 다른 모든 범주와 구별하고 시각적 인식을 위해 표현을 보다 계층적이고 의미있게 만들기 위한 classifier 필요
     - 일반적으로 Supported Vector Machine (SVM), AdaBoost, Deformable Part-based Model (DPM) 이 좋은 성능을 보임.
     - 2012년 이후 앙상블 시스템을 구축하고 약간의 변형을 사용하여 성능을 올림.
       - 슬라이딩 윈도우를 사용하는 bounding box(BB)의 생성이 중복되고 비효율적이며 부정확
       - R-CNN 제안 이후, classification과 BB  회귀 작업을 최적화 하는 Fast R-CNN 제안
       - YOLO(you only look once) : fixed-grid regression을 통해 객체 감지 수행
     - CNN 구조에서 일반적인 객체 감지는 BB 회귀 사용
     - salient object detection은 local contrast enhancement, 픽셀 수준 분할로 수행

- Object Detection 응용 분야

![그림 1.-물체 감지의 응용 영역.](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/5962385/8886738/8627998/zhao1-2876865-small.gif)



## CNN architecture

<hr>

- CNN의 각 층은 feature map이라고 함.
- 입력층의 feature map은 서로 다른 색상 채널(e.g. RGB)에 대한 픽셀 강도의 3D 행렬
- internal layer의 feature map은 유도된 멀티 채널 이미지, 픽셀은 특정 기능
- 모든 뉴런은 이전 계층의 인접 뉴런의 small portion에 연결됨.
- 필터링 연산은 뉴런의 receptive filed 값으로 필터 행렬을 컨볼루션하고 sigmoid, ReLu와 같은 비선형 함수를 사용
- 풀링 작업은 receptive filed 응답을 하나의 값으로 요약
  - Pooling operation : max pooling, average pooling, L2-pooling and local contrast normalization
- 컨볼루션과 풀링 사이에 interleave를 사용하면 initial feature hierarchy이 구성됨.
  - 여러 개의 Fully-Connected 층을 추가하여 서로 다른 시각적 작업에 조정 가능
  - 다른 활성화 함수를 가진 최종 레이어 각 출력 뉴런에 대한 특정 조건부 확률을 얻기 위해 추가됨
- 전체 네트워크는 stochastic gradient descent(SGD)를 통해 목적함수(평균제곱오차(MSE) or 교차 엔트로피 손실)을 통해 최적화

- The advantages of CNN
  - Hierarchical feature representation을 데이터로부터 자동 학습
  - 입력 데이터의 hidden factor는 다단계 비선형 매핑을 통해 분리될 수 있음.

![A CNN that sees an image of a car and outputs a class.](https://cezannec.github.io/assets/cnn_intro/CNN_ex.png)



## Generic object detection architectures

<hr>

- 하나의 이미지에서 기존 객체를 찾아 분류(classifying)하고 직사각형 바운딩박스로 레이블을 지정하여 confidences of existence 표시

- 객체 감지 프레임워크

  - ### Region Proposal Based Framework

    1. 기존의 객체 감지 파이프라인을 따라, region proposals를 생성 후 각 제안을 서로 다른 객체 카테고리로 분류
       - R-CNN, SPP-net, Fast R-CNN, Faster R-CNN, R-FCN, FPN, Mask R-CNN 
    2. 영역 제안 기반 프레임워크 : 전체 시나리오 스캔 후 regions of interest(ROI)에 초점을 맞춤
       - 대표적으로 Overfeat 모델은 CNN을 슬라이딩 윈도우 방법에 삽입하여 객체 카테고리의 신뢰도를 얻은 후 최상위 feature map의 위치에서 직접 BB 예측

    - **R-CNN**

      - 순서
        1. Region proposal generation
           - selective search를 채택하여 각 이미지에 대해 약 2,000개의 region proposals 생성
             - selective search : 임의의 크기보다 정확한 candidate box를 제공 및 객체 감지에서 검색 공간 감소
        2. CNN based deep feature extraction
           - 각 region proposal은 고정된 해상도로 뒤틀리거나 잘림.
           - 높은 수준의 의미론적 feature 확보
        3. Classification and localization
           - 여러 클래스에 대해 사전 훈련된 카테고리별 linear SVM을 사용하여 긍정/부정 영역에 대한 점수 매김
           - 각 영역은 bounding box regression와 탐욕적 non-maximum suppression(NMS)로 필터되어 보존된 객체 위치에 최종 BB 생성

      ![img](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/5962385/8886738/8627998/zhao3-2876865-large.gif)

      - The disadvantages of R-CNN
        1. FC 레이어의 존재로 인해 고정된 크기의 입력 이미지의 평가 영역에 대한 CNN의 재 계산으로 많은 시간 소요
        2. R-CNN의 훈련은 다단계 파이프 라인임.
           - 객체 제안에 대한 ConvNet 미세 조정, 소프트맥스가 SVM으로 대체, 경계 상자 회귀자 훈련
        3. 선택적 검색은 상대적으로 high recall region proposal을 생성하지만, 기존의 proposal은 여전히 중복

    - **SPP-Net**

      - R-CNN의 FC 층은 고정된 크기를 입력 받아야 하므로, 이 과정에서 잘린 영역에 개체가 존재하거나 뒤틀림으로 인해 왜곡이 발생할 수 있다는 문제 개선을 위해 spatial pyramid matching(SPM) 이론을 고려하여 새로운 구조 제안
      - 5번째 conv 층의 feature map을 재 사용하여 임의 크기의 영역 제안을 고정 길이 feature vector에 투영
      - 서로 다른 region proposal을 올바르게 추정하여 더 나은 결과 확보 및 spatial pyramid pooling layer(최종 전환 층의 다음 층, SPP) 계층 이전에 계산 비용을 공유하여 테스트 기간의 감지 효율성 향상

      ![img](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/5962385/8886738/8627998/zhao4-2876865-large.gif)
      
    - **Fast R-CNN**

      - SPP-net은 특징 추출, network fine-tuning, SVM 훈련및 BB 회귀를 포함하여 R-CNN과 거의 동일한 다단계 파이프라인

        - SPP-net은 여전히 추가 저장 공간이 필요함.
        - SPP 층 이전의 conv 층 업데이트가 불가능
        - 이를 위해 분류, BB 회귀에 대한 multi-task loss를 제시

      - 구조

        - feature map을 생성하기 위해 conv 레이어로 처리
        - 이후, ROI 풀링 레이어가 있는 각 region proposal에서 고정 길이 특징 벡터 추출
          - ROI 풀링 레이어는 피라미드레벨이 하나인 SPP의 특수한 경우
        - 각 특징 벡터는 두 개의 sibling 출력층으로 분기되기 전 FC 층으로 공급
        - 하나의 출력 계층은 모든 항목에 대해 소프트맥스 확률 생성

        - 그 외의 출력 계증은 4개의 실 수 값으로 정제된 BB 위치를 인코딩
        - 상기 절차의 모든 매개 변수(region proposals의 생성 제외)는 end-to-end 방식의 multi-task loss를 통해 최적화 됨.

        ![Fast R-CNN.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/Fast%20R-CNN.PNG?raw=true)

      - 파이프라인 가속화를 위한 트릭

        - 훈련 샘플(i.e. ROI)이 다른 이미지로 부터 나온 경우 SPP  계층을 통한 역전파는 매우 비효율적
        - CNN 샘플 계층적으로 미니배치
        - 계산과 메모리는 순전파, 역전파에서 동일한 이미지의 RoI에 의해 공유됨.
        - 반면, 순전동안 FC 계층을 계산하는데 많은 시간 소요
        - truncated Singlular Value Decomposition(SVD)는 대형 FC층을 압축하고 테스트 절차를 가속화 하는데 사용

      - region proposal 생성에 관계없이 모든 네트워크층의 훈련을 multi-task loss로 하나의 단계로 처리 가능

      - 저장 공간에 대한 추가 비용 절약, 합리적인 train scheme를 통해 정확성과 효율성 향상

    - **Faster R-CNN**

      - 최신 객체 탐지 네트워크는 격리된 region proposal 후보 풀 생성을 위해 주로 추가 방법에 의존

        - 추가 방법 : selective search, Edgebox

      - region proposal 계산은 효율성 향상에 있어 병목 현상임.

      - 이를 해결하기 위해 **Region Proposal Network(RPN)을 추가 도입**

        - 이는 탐지 네트워크와 이미지 전환 기능을 공유하여 거의 비용이 들지 않는 방식

        - 각 위치에서 동시에 object bounds, score를 예측 기능이 있는 FCN으로 달성

        - 객체 감지 네트워크를 공유하는 이전 계층의 특정 conv 층에서 동작

        - RPN 구조

          - 저차원 벡터가 각 슬라이딩 창에서 얻어짐.
          - box-classification layer(cls), box-regression layer(reg)에 공급
          - n x n conv층 다음에 1 x 1 sibling conv 층으로 구현

          ![RPN.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/RPN.PNG?raw=true)

      - Faster R-CNN의 제안으로 객체 감지를 위한 region proposal 기반 CNN 구조는 end-to-end 방식으로 훈련될 수 있음.

      - 학습 시간이 길고, 객체 인스턴스 대신 RPN region 같은 개체(배경 포함)를 생성하고, 극단적인 크기나 모양을 가진 객체에는 적합하지 않음.
      
    - **R-FCN**

      - 객체 감지를 위한 RoI 풀링 계층은 두 개의 서브 네트워크로 구성
        - 공유된 fully convolutional subnetwork(RoI와 독립적), 비공유 RoI 방식 서브 네트워크
        - 이것은 특정 공간 풀링 레이어로 분리된 여러 FC층과 convolutional subnetwork 구성에서 비롯됨.(AlexNet, VGG16)
      - ResNet, GoogLeNets 같은 최신 이미지 분류 네트워크는 fully convolutional 임.
        - 상기 아키텍처에 적용하기 위해서는 RoI 방식의 fully convolutional로 구성해야 하지만, native solution에서는 성능이 열등함이 밝혀짐.
        - 이미지 내에서 객체를 이동하는 것은 이미지 분류에서 무차별 적이어야 함.
      - Faster R-CNN과 달리, R-FCN의 각 카테고리에 대해, 마지막 conv 층은 우선 K x K의 fixed grid를 사용하여 총 K^2개의 position-sensitive score 맵을 생성하고, 집계를 위해 position-sensitive RoI 풀링 층이 추가됨.
      - 마지막으로, 각 RoI에서 K^2개의 position-sensitive score는 평균을 내어 conv 층에 추가되어 클래스에 구애받지 않는 BB를 얻음.
      - 강력한 분류 네트워크를 채택하여 거의 모든 층을 공유함으로써 fully convolutional 구조에서 객체 감지 수행

    - **FPN**

      - (a) 피처 피라미드를 만들기 위해 이미지 피라미드를 사용하는 것이 느림. 
      - (b) 빠른 감지를 위해 single-scale feature만 채택
      - (c) 기능화 된 이미지 피라미드의 대안은 ConvNet에 의해 계산 된 피라미드 feature 계층을 재사용하는 것임. 
      - (d) FPN은 (b)와 (c)를 모두 통합
        - 파란색 윤곽선은 feature map을 나타내고 두꺼운 윤곽선은 의미 상 더 강력한 feature를 나타냄.

      ![FPN.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/FPN.PNG?raw=true)

      - 피처 피라미드는 모든 단계에서 풍부한 의미를 추출하고 모든 scale로 끝에서 끝으로 훈련될 수 있으므로, 속도와 메모리를 희생하지 않음.
      - FPN은 backbone CNN 구조와 독립적이며, 여러 단계의 객체 감지(e.g., region proposal generation) 및 기타 컴퓨터 비전 작업(e.g., instance segmentation)에 적용됨.

    - **Mask R-CNN**

      - 분류 및 BB 회귀를 위한 Faster R-CNN의 기존 분기분기와 병행하여 Mask R-CNN은 분기를 추가하여 pixel-to-pixel 방식으로 segmentation mask 예측
      - segmentation mask branch는 명시적 객체 공간 레이아웃을 유지하기 위해 M x M 마스크를 인코딩
        - 이러한 fully convolutional 표혀은 더 적은 매개 변수를 필요로 더 정확함.
      - 분류, BB 회귀에 대한 손실 외에도 segmentation mask 분기에 대한 추가 손실이 다중 작업 손실에 정의됨.
        - 해당 손실은 ground-truth 클래스와만 연관
        - 분류 분기에 의존하여 카테고리 예측
      - Faster R-CNN의 RoI 풀링은 특징 추출을 위한 공간 양자화 수행으로 인해 RoI와 특징간에 정렬 불량 발생
        - 이는 fixel-to-pixel 마스크 예측에 큰 부정적 영향
        - 이를 위해 Mask R-CNN은 양자화가 없는 레이어, RoIAlign을 채택하여 명시적인 픽셀 당 공간 대응을 보존
          - RoIAlign은 RoI 풀링의 양자화를 bi-linear interpolation으로 대체
          - 각 RoI bin에서 4개의 위치에서 샘플링되는 입력 특성의 정확한 값 계산
          - 엄격한 localization metrics에서 마스크 정확도 크게 향상
      - Mask R-CNN은 instance-level recognition을 위한 유연하고 효율적인 프레임 워크
        - 다른 작업(e.g., human pose estimation)으로 쉽게 일반화 가능

    - **Multitask Learning, Multiscale Representation, and Contextual Modeling**

      - Faster R-CNN의 많은 제안으로 유망한 결과를 얻었으나, feature map의 조잡함과 특정 candidate box에 제공된 제한된 정보로 소형 물체 감지 및 위치 파악이 어려움.
        - 이를 해결하기 위해 여러 소스의 보완 정보를 결합해야 함.
          - Multitask learning, Multiscale representation, Contextual modeling

    - **Deep Learning-Based Object Detection**

      - ResNets, GoogLeNets
        - 특징 추출에 집중하는 대신 객체 분류기에 대한 자세한 분석 수행
        - deep, convolutional 영역별 classifier를 신중하게 구성하는 것이 객체 감지에 매우 중요함.
      - Subcategory-aware CNN
        - 기존의 CNN 프레임 워크는 2D 객체 감지만 관련된 경우 큰 규모 변화, 폐색 또는 절단을 처리하는데 능숙하지 않음.
        - 물체 포즈와 관련된 하위 코테고리 정보로 region proposal 생성을 안내하고 객체 감지 및 하위 카테고리 분류를 공동으로 최적화
      - Factors in finetuning deep model with long-tail distribution
        - 서로 다른 수의 샘플을 가진 클래스가 특성 학습에 각기 다른 영향을 미침.
        - 우선 객체를 시각적으로 유사한 클래스 그룹으로 클러스터링 한 후 계층적 특징 학습 체계를 채택하여 각 그룹에 대한 심층 표현을 개별적으로 학습

  - ### Regression/Classification Based Framework

    - 이미지 픽셀에서 BB 좌표, 클래스 확률로 직접 매핑하는 global regression, classification을 기반으로 하는 One-step 프레임워크는 시간 비용을 줄일 수 있음.

    - **Pioneer Works**

      - DNN 기반 회귀 공식을 이용한 객체 감지 작업
        - 테스트 이미지에 대한 이진 마스크 생성 후 간단한 BB 추론으로 감지를 추출
        - 겹치는 물체를 처리하기 어렵고, direct upsampling으로 생성된 BB는 완벽하지 않음.
      - CNN model with two branches
        - 클래스에 구애받지 않는 분할 마스크 생성, 객체 중심 패치 가능성 예측
        - CNN 작업이 공유되는 단일 모델에서 클래스 점수 및 세분화를 얻을 수 있음.
      - regression-based MultiBox
        - 클래스에 구애받지 않는 BB 좌표 예측을 위해 여러 구성 요소의 localization과 신뢰도를 편향시키기 위해 통합 손실 도입
        - 많은 추가 매개 변수가 최종 레이어에 도입됨.
      - impressive end-to-end CNN architecture(AttentionNet)
        - 양좌화 된 weak direction을 생성하여 대상 객체를 가리키고 반복 예측 앙상블을 사용하여 정확한 물체 BB로 수렴
        - 여러 범주를 처리할 때 매우 비효율적
      - proposal-free iterative grid-based object detector(G-CNN)
        - 객체 감지를 fixed grid에서 객체를 밀접하게 둘러싼 상자로 모델링
        - regressor를 훈련시켜 그리드의 요소를 객체쪽으로 반복적으로 이동하고 크기 조정
        - 작거나 겹치는 물체를 처리하는데 어려움.

    - **YOLO**

      - 전체 최상위 feature map을 사용하여 여러 카테고리와 BB에 대한 신뢰도 예측

      - YOLO의 아이디어

        1. 입력이미지를 S x S 그리드로 나누고 각 그리드 셀은 해당 그리드 셀의 중심에 있는 객체 예측

        2. 각 그리드 셀 B는 BB 및 BB의 신뢰 점수 예측

           - 신뢰 점수(개체가 존재할 가능성) 예측

           ![YOLO-1.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/YOLO-1.PNG?raw=true)
           
           - 조건부 클래스 확률은 각 그리드 셀에서도 예측되어야 함.
             
             - 객체를 포함하는 그리드 셀의 기여도만 계산
             
             ![YOLO-2.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/YOLO-2.PNG?raw=true)
             
           - 테스트 시간에 각각의 box에 대한 클래스 별 신뢰도 점수
           
             - 각 box의 신뢰도 : 예측과 조건부 클래스 확률의 곱
           
             ![YOLO-3.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/YOLO-3.PNG?raw=true)
           
           - 훈련 중 손실 함수가 최적화 됨.
           
           ![YOLO-4.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/YOLO-4.PNG?raw=true)
           
           - 객체가 해당 그리드 셀에 있는 경우에만 손실 함수가 분류 오류에 패널티를 적용
           - 해당 그리드 셀에 있는 모든 predicator의 가장 높은 IoU가 달성되면 BB 좌표 오류 벌점 부여
           
           ![YOLO.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/YOLO.PNG?raw=true)
           
           - 24개의 conv 층, 2개의 FC 층으로 구성
             - 일부 conv 층은 1 x 1 reduction 층, 3 x 3 conv 층으로 시작 모듈의 앙상블 구성
  
- YOLO는 백그라운드에서 적은 false positive 생성으로 Fast R-CNN과 협력 가능
      - YOLO v2는 BN, anchor boxes, 차원 클러스터 및 멀티스케일 훈련과 같은 전략 채택
    - **SSD**
      - YOLO는 BB 예측에 부과된 공간적 제약으로 인해 작은 객체를 처리하는 데 어려움이 있음.
      - YOLO는 여러 다운 샘플링 작업으로 인해 상대적으로 coarse feature를 생성
      - 특정 feature map이 주어지면 YOLO에 채택된 고정 그리드 대신 BB의 출력 공간을 구분하기 위해 종횡비와 스케일을 가진 기본 앵커 박스 세트 활용
      - 다양한 크기의 객체 처리를 위해 해상도가 다른 여러 feature map 예측 융합
      - SSD 아키텍처
        - VGG16 backbone 구조를 고려하여 네트워크 끝에 여러 feature layer를 추가
          - 다양한 스케일, 종횡비, 관련 신뢰도를 사용하여 기본 box에 대한 오프셋 예측
        - 네트워크는 지역화 손실(eg., Smooth L1) 및 신뢰 손실(eg., softmax)의 가중치 합으로 훈련됨.
        - 다중 스케일 정제 BB에서 NMS(nonmaximum suppression)를 수행하여 결과를 얻음.
        
        ![SSD.PNG](https://github.com/devLupin/TIL/blob/master/AI/02.%20Object%20Detection/02.%20Reviews/image%20source/SSD.PNG?raw=true)
      - PASCAL VOC 및 COCO의 정확도 측면에서 Faster R-CNN보다 성능이 훨씬 뛰어나고 3배 더 빠름.
      - SSD는 작은 객체를 처리하는데 능숙하지 않음.(eg., stem block, dense block)

