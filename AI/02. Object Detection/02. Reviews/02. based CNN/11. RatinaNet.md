# **RetinaNet (Focal Loss for Dense Object Detection)**

<hr>

- object detection 모델은 이미지 내의 객체의 영역을 추정하고 IoU threshold에 따라 positive/negative sample로 구분한 후, 학습
- 그러나, 일반적으로 이미지 내 객체의 수가 적기 때문에 positive sample(객체 영역)은 negative sample(배경 영역)에 비해 적음.
  - 이로 인해, positive/negative sample 사이에 큰 차이가 생겨 class imbalance 문제 발생

- Class imbalance
  - 대부분의 sample이 모델이 class를 예측하기 쉬운 sample(easy negative)이므로 유용한 기여를 하지 못함.
  - easy negative의 수가 압도적으로 많기 때문에 학습에 끼치는 영향력이 커져 모델의 성능 하락

- Two-stage detector 계열 모델의 등장
  - **region proposals**를 추려내는 방법을 적용하여 대부분의 background sample을 걸러주는 방법 사용
    - selective search, edgeboxes, deepmask, RPN 등
  - positive/negative sample의 수를 적절하게 유지하는 **sampling heuristic** 방법 적용
    - hard negative mining, OHEM 등
  - 기술된 방법들은 one-stage detector에 적용하기 어려움.
    - region proposal 과정이 없어 전체 이미지를 순회하면서 sampling하는 dense sampling 방법을 수행하기 때문에 two-stage보다 훨씬 많은 후보 영역 생성

- 본 논문은 학습 시 training imbalance가 주된 문제로 보고, 이 문제를 one-stage detector에서 적용할 수 있는 새로운 loss function



## Preview

<hr>

- **Focal loss**라는 새로운 loss function 제시

  - cross entropy loss에 class에 따라 변하는 동적인 scaling factor를 추가한 형태
  - easy example의 기여도를 자동적으로 down-weight, hard example에 대해서 가중치를 높혀 학습에 집중시킴.

- RetinaNet은 ResNet-101-FPN을 backbone network로 가지며, anchor boxes를 적용하여 기존의 two-stage detector에 비해 높은 성능

  ![img](https://blog.kakaocdn.net/dn/DsRg4/btqWWsTsmDN/nckkQnI21549nkiLMruNr1/img.png)



## Focal Loss

<hr>

- one-stage detector 모델에서 foreground와 background class 사이에 발생하는 극단적인 class imbalance(가령 1:1000)문제를 해결하는데 사용
- 이진 분류에서 사용되는 Cross Entropy(이하 CE) loss function으로부터 비롯됨.

### CE loss

- 모든 sample에 대한 예측 결과를 동등하게 가중치 부여

  - 어떠한 sample이 쉽게 분류될 수 있음에도 불구하고 작지 않은 loss 유발
  - 많은 수의 easy example의 loss가 더해지면 보기 드문 class를 압도하여 학습이 제대로 이뤄지지 않음.

  $$
  CE(p, y)= \begin{cases} -log(p), & \mbox{if }\mbox y=1 \\ -log(1-p), & \mbox otherwise \end{cases}
  \ \\ \ \\ \ \\
  p_t = \begin{cases} p, & \mbox{if }\mbox y=1 \\ 1-p, & \mbox otherwise \end{cases}
  \ \\ \ \\ \ \\
  y \in [1, -1] : ground\ truth\ class
  \ \\
  p \in [0, 1] : 모델이\ y=1이라고\ 예측한\ 확률
  $$

- 



### Balanced Cross Entropy

- 상기 문제 해결을 위해 가중치 파라미터 α를 곱해준 Balanced Cross Entropy
- y=1일 때 α를 곱해주고, y=−1일 때 1−α를 곱함.
- Balanced CE는 positive/negative sample 사이의 균형을 잡아주지만, easy/hard sample에 대해서는 균형을 잡지 못함.

$$
CE(p_t) = -\alpha log(p_t)
\ \\ \ \\ \ \\
\alpha \in [0, 1]
$$



### Focal Loss

-  easy example을 down-weight하여 hard negative sample에 집중하여 학습하는 loss function

- **modulating factor (1−p_t)^γ와 tunable focusing parameter γ를 CE에 추가한 형태**
  $$
  FL(p_t)= \begin{cases} -(1-p_t)^{\gamma} log(p_t), & \mbox{if }\mbox y=1 \\ -(1-(1-p_t))^{\gamma} log(1-p_t), & \mbox otherwise \end{cases}
  $$

- 서로 다른 γ ∈[0,5] 값에 따른 loss

  - 파란선은 cross entropy
    - 경사가 완만하여 p_t가 높은 example과 낮은 example 사이의 차이가 크지 않다는 것을 확인

  ![img](https://blog.kakaocdn.net/dn/dZ8Fdd/btqWLYftI8z/D2zcPLUyQX78U1pypNqrPK/img.png)

  ![img](https://blog.kakaocdn.net/dn/AlDob/btqWUqWDoSL/HE02swJYTRwo6APNQ4wFMk/img.png)

- Focal loss는 focusing parameter γ에 따라 p_t가 높은 example과 낮은 example 사이의 차이가 상대적으로 큼.

- Focal loss 특성

  1. p_t와 modulating factor와의 관계
     - example이 잘못 분류되고, p_t가 작으면, modulating factor는 1과 가까워지며, loss는 영향을 받지 않음.
     - p_t 값이 크면, modulating factor는 0에 가까워지고, 잘 분류된 example의 loss는 down-weight 됨.
  2. focusing parameter γ의 역할
     - easy example을 down-weight하는 정도를 부드럽게 조정
     - γ가 0인 경우, focal loss는 CE와 같고, γ가 상승할수록 modulating factor의 영향력이 커지게 됨.
     - 논문에서는 γ=2일 때, 성능이 가장 좋았다고 함.

  - modulating factor는 easy example의 기여도를 줄이고, example이 작은 loss를 받는 범위를 확장시키는 기능
    - 잘못 분류된 example을 수정하는 작업의 중요도 상승



## RetinaNet

<hr>

- one-stage detector
- 하나의 backbone network, classification과 BB regression을 수행하는 2개의 sub network로 구성



## Training RetinaNet

<hr>

## 1) Feature Pyramid by ResNet + FPN

- 이미지를 **backbone network**에 입력하여 서로 다른 5-scale의 feature pyramid 출력
  - backbone network로 **ResNet 기반의 FPN** 사용
    - pyramid level은 P3 ~ P7로 설정

- **Input** : image
- **Process** : feature extraction by ResNet + FPN
- **Output** : feature pyramid(P5~P7)

## 2) Classification by Classification subnetwork

- pyramid level별 feature map을 Classification subnetwork에 입력
- subnet은 **3x3(xC) conv layer - ReLu - 3x3(xKxA) conv layer**로 구성
  - K는 분류하고자 하는 class 수, A는 anchor box 수
    - 논문에서는 A=9
- 마지막으로 얻은 feature map의 각 spatial location(feature map의 cell)마다 sigmoid activation function 적용

- **Input** : feature pyramid(P5~P7)
- **Process** : classification by classification subnetwork
- **Output** : 5 feature maps with KxA channel 

## 3) Bounding box regression by Bounding box regression subnetwork

- 1)에서 얻은 각 pyramid level별 feature map을 **BB regression subnetwork**에 입력
  
  - subnet은 FCN임.
- feature map이 anchor box별로 4개의 좌표값(x, y, w, h)을 encode하도록 channel 조정

- **Input** : feature pyramid(P5~P7)

- **Process** : bounding box regression by bounding box regression subnet

- **Output** : 5 feature maps with 4xA channel

  ![img](https://blog.kakaocdn.net/dn/qjSwj/btqWTYe0Nzt/jYBgbiNmSdaBIYiVTY8yMk/img.png)



## Inference

<hr>

- 속도를 향상시키기 위해 각 FPN의 pyramid level에서 가장 점수가 높은 1000개의 prediction만을 사용

- 2개의 subnetwork의 출력 결과에서 모든 level의 예측 결과는 병합되고, **Non maximum suppression(**threshold=0.5)를 통해 최종 예측 결과 산출

  

- RetinaNet Performance

  ![img](https://blog.kakaocdn.net/dn/bE9dQX/btqWUqbqYCJ/9XS6NhaAqmBDRyZKbvVh5k/img.png)

  

- OHEM은 class imbalance 문제를 해결하기 위해 별도의 네트워크(read-only RoI network)를 설계한 반면, 본 논문에서는 loss function을 수정하는 비교적 단순한 방법으로 성능을 향상