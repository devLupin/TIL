# **SSD(Single Shot MultiBox Detector)**

<hr>

- VGG16을 base network로 사용하고 보조 network(auxiliary network)를 추가한 구조
- 두 network를 연결하는 과정에서 FC layer를 Conv layer로 대체하면서 detection 속도 향상
- Convolutional Network 중간의 Conv layer에서 얻은 feature map을 포함시켜, **6-scale의 feature map 예측 및 사용**
- feature map의 각 cell마다 서로 다른 scale과 aspect ratio를 가진 BB인 **default box를 사용**하여 객체 위치 추정

![img](https://blog.kakaocdn.net/dn/cEHNEN/btqSa9Yb4qh/txKuruXq2rNmYYQzTeXHn1/img.png)



# Main ideas

<hr>

## 1. Multi-scale feature maps

- 하나의 통합된 네트워크로 detection을 수행하는 1-stage detector(YOLO v1과 동일)

- **pre-trained VGG16을 base network로 사용하고, 이후 보조 network를 추가한 구조**

  - 보조 network는 일반적인 Conv layer로 구성

- base network 후반에 등장하는 FC layer를 Conv layer로 바꿔 보조 network와 연결

  - FC layer가 제거되며 detection 속도 향상

  ![img](https://blog.kakaocdn.net/dn/bqCXJJ/btqSduunMMA/AS6yMzCgHXMa1V72KCQBO1/img.png)

- 다양한 scale의 feature map 사용

  - 기존에는 convolutional network를 거친 단일 scale을 가진 feature map 사용
    - YOLO v1의 경우 7x7x30크기의 feature map
    - **이는 다양한 크기의 객체 포착이 어려움.**
  - SSD는 network 중간에 존재하는 conv layer의 feature map을 추출하여 detection 시 사용
    - 총 6개의 scale을 가진 feature map 확보
    - **Multi-scale feature map을 사용하여 다양한 크기의 객체 탐지 가능**



## 2. Default boxes

- 다양한 크기의 객체 탐지를 위해 feature map의 각 cell마다 서로 다른 scale과 aspect ratio를 가진 Default box 생성
  - 서로 다른 크기의 feature map에 적용
  - 38x38, 19x19, 10x10, 5x5, 3x3, 1x1 총 6개의 scale의 feature map의 각 cell마다 default box 생성
- Default box의 scale = 원본 이미지에 대한 비율
  - m : 예측에 사용될 feature map의 수

$$
s_k = s_{min} + {{s_{max} - s_{min}} \over {m-1}} (k-1), k \in [1, m]
\ \\
s_{min} = 0.2
\ \\
s_{max} = 0.9
\ \\
m = 6
$$

- feature map의 scale이 작아질수록 default box의 scale은 커짐.
- feature map의 크기가 작아질수록 더 큰 객체를 탐지할 수 있음을 의미



## 3. Predictions

- 각각의 feature map은 서로 다른 수의 default box 적용
- feature map의 각 cell마다 4개의 default box를 적용
  - 첫 번째(38x38)와 마지막(1x1) feature map은 aspect ratio가 1:1, 1:2, 1:1/2인 box와 aspect ratio
  - (1:1일 때 추가적으로 사용하는) box

![img](https://blog.kakaocdn.net/dn/q2TfL/btqSa8S2vJK/T4wNnc6Ot63swimTBrAq40/img.png)

- 최종 예측을 위해 서로 다른 scale의 feature map을 추출한 후 3x3 Conv(stride=1, padding=1) 연산 적용
  - default box의 수 k, 예측하려는 class의 수 C일 때, **output feature map의 channel 수는 k(4+c)**
    - 각 feature map의 cell이 k개의 default box를 생성하고 각 box마다 4개의 offset과 class score를 예측
  - class의 수는 배경을 포함하여 C+1

![img](https://blog.kakaocdn.net/dn/bpcmxo/btqRXGXUIcS/qFfch5Xk8keVDixu3xMRM0/img.png)



## 4. Maching strategy

- 학습 진행 시, default box의 학습 대상을 지정하기 위해 어떤 default box가 어떤 ground truth box와 대응하는지 결정
  - **default box, ground truth box 매칭 작업** 필요
    - ground truth box, 가장 큰 jaccard overlap(=IoU)를 가지는 box와 IoU가 0.5 이상인 box는 모두 positive로 label
    - 그 외의 box는 negative로 label
  - 일반적으로 이미지 내 background에 해당하는 box가 많아 negative sample의 수가 훨씬 많음.
    - 클래스 불균형(class imabalance) 문제 발생
    - 이를 해결하기 위해 높은 confidence loss를 가진 sample을 추가하는 hard negative mining 수행
      - 이 때 positive : negative = 1 : 3



## 5. Loss function

- confidence loss, localization loss의 합으로 구성

- α는 두 loss 사이의 가중치를 조절하는 balancing parameter

  - 디폴트 값으로 1 사용

- N은 ground truth box와 매칭된 default box의 수

  - N=0, loss=0

- localization loss

  - default box의 중심 좌표(cx, cy)와 너비/높이(w, h)를 사용하여 smooth L1 loss를 통해 구함.

    - Faster R-CNN과 동일한 방식

  - l은 예측한 box 파라미터(좌표), g는 groudn truth box의 파라미터(좌표)를 의미

  - x^k_{i,j}는 i번째 default box와 class가 k인 j번째 ground truth box와의 매칭 여부를 알려주는 indicator parameter

    - 매칭 시 1, 그렇지 않은 경우 0

    $$
    L_{loc}(x, l, g) = \sum_{i \in Pos}^N \sum_{m \in {cx, cy, w, h}} x_{ij}^k smooth_{L1}(l_i^m - \hat{g_j^m})
    $$

- confidence loss

  - 모든 class에 대한 loss를 softmax loss를 통해 계산

  $$
  L_{conf}(x, c) = - \sum_{i \in Pos}^N x_{ij}^p log(\hat{c_i^p}) - \sum_{i \in Neg} log(\hat{c_i^0}) \ where \ \hat{c_i^p} = {{exp(c_i^p)} \over {\sum_p exp(c_i^p)}}
  $$



# Training SSD

<hr>

## 1. Network 구성

- 학습을 위해 base network, auxiliary network를 합쳐 전체 네트워크 구성
- pre-trained VGG16모델에서 마지막 2개의 FC layer를 Conv layer로 대체
- 이후, 최종 output feature map의 크기가 1x1이 되도록 auxiliary network 설계

## 2. 이미지 입력 및 서로 다른 scale의 feature map

- SSD network에 300x300 크기의 이미지 입력
- 전체 network 구간 중 conv4_1, conv7, conv8_2, conv9_2, conv10_2, conv11_2 layer에서 각각 feature map 추출
- **Input** : 300x300 sized imaeg
- **Process** : feature map extraction
- **Output** 
  - 38x38(x512) sized feature map
  - 19x19(x1024) sized feature map
  - 10x10(x512) sized feature map
  - 5x5(x256) sized feature map
  - 3x3(x256) sized feature map
  - 1x1(x256) sized feature map

## 3. 각 scale의 feature map에 Conv 연산 적용

- **각 scale feature map에 3x3 Conv(stride=1, padding=1) 연산 적용**
- **각 feature map마다 서로 다른 수의 default box 사용**
- **Input** : 6 feature maps
- **Process** : 3x3 conv(stride=1, padding=1)
- **Output** 
  - 38x38(x4x(21+4)) sized feature map
  - 19x19(x6x(21+4)) sized feature map
  - 10x10(x6x(21+4)) sized feature map
  - 5x5(x6x(21+4)) sized feature map
  - 3x3(x6x(21+4)) sized feature map
  - 1x1(x4x(21+4)) sized feature map

## 4. 전체 feature map 병합

- feature map을 8732 x (21+4) 크기로 병합
- default box별 BB offset 값, class score 파악 가능
- **Input** : 6 feature maps
- **Process** : merge feature maps
- **Output** : 8732 x (21+4) sized feature map

## 5. loss function을 통한 학습

- hard negative mining 수행
  1. feature map, ground truth 정보를 이용해 localization loss 계산
  2. negative sample에 대한 cross entropy loss를 구한 후, loss에 따른 내림차순 정렬
  3. loss가 높은 순으로 positive sample의 3배만큼의 수 추출
- 얻어진 hard negative sample, positive sample을 사용하여 confidence loss 계산
- localization loss, confidence loss를 더해 최종 loss를 구한 후 backward pass를 수행



# Detection

<hr>

- 마지막 예측에 대하여 Non maximum suppression 수행
- 이를 통해 겹치는 default box를 제거하여 정확도 향상



# 결론

<hr>

- 다양한 scale의 feature map에 다양한 scale과 aspect ratio를 가진 default box를 생성하여 다양한 크기를 가진 객체 포착
- 전체 network가 분리되어 있지 않아 빠른 속도의 detection 가능