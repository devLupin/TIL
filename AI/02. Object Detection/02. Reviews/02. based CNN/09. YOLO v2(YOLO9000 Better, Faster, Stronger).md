# **YOLO v2(YOLO9000:Better, Faster, Stronger)**

<hr>

- SSD300 모델은 detection 속도가 빠르지만 정확도가 낮으며, SSD512 모델은 정확도는 높지만 detection 속도가 느림.
- 몇 가지 아이디어를 도입하여 정확도와 속도 사이의 균형을 맞춘 성능
- Better : 정확도를 올리기 위한 방법
- Faster : detection 속도를 향상시키기 위한 방법
- Stronger : 더 많은 범위의 class를 예측하기 위한 방법



# Main Ideas

<hr>

## Better

<hr>

### 1. Batch Normalization

- 모든 Conv layer 뒤에 batch normalization 추가
  - mAP 값 % 향상
- overfitting없이 기타 regularization, dropout 제거

### 2. high Resolution Classifier

- YOLO v1 모델은 Darknet을 224x224 크기로 pre-train, detection task 시에는 448x448 크기의 이미지를 입력으로 사용
  - 네트워크가 object detection task를 학습하면서 동시에 새로운 입력 이미지의 resolution(해상도)에 적응
- YOLO v2 모델은 처음부터 Darknet을 448x448 크기로 pre-train시켜 네트워크가 상대적으로 높은 해상도의 이미지에 적응할 시간 제공
  - mAP 값이 4% 정도 향상

### 3. Convolutional with Anchor boxes

- YOLO v1은 각 grid cell의 bounding box의 좌표가 0~1 사이의 값을 가지도록 랜덤으로 설정한 뒤 학습을 통해 최적의 값 탐색
- Faster R-CNN 모델은 사전에 9개의 anchor box를 정의한 후 bounding box regression을 통해 x, y 좌표와 aspect ratio(offset)을 조정
  - **좌표 대신 offset을 예측하는 문제가 보다 단순하고 네트워크가 학습하기 쉬움**
- YOLO v2에서는 **anchor box**를 도입해 네트워크를 수정
  - conv layer의 output이 보다 높은 resolution을 가지도록 pooling layer 제거
  - 이미지를 448x448 크기에서, 네트워크를 줄여 416x416 크기의 입력 이미지를 사용
    -  최종 output feature map의 크기가 홀수가 되도록 하여, feature map 내에 하나의 중심 cell이 존재할 수 있도록 하기 위함
      - 보통 객체의 크기가 큰 경우 이미지 내에서 중심을 차지하기 때문에, 하나의 중심 cell이 있으면 이를 잘 포착할 수 있기 때문
    -  최종적으로 13x13 크기의 feature map을 얻음.
  - **anchor box를 통해 더 많은 수의 BB를 예측하면서 실제 객체의 위치를 보다 잘 포착하게 되고, 이를 통해 recall 값이 상승**
    - **recall 값이 높다는 것은 모델이 실제 객체의 위치를 예측한 비율이 높음을 의미**

### 4. Dimension Clusters

- **k-means clustering**을 통해 최적의 prior를 탐색하는 방법 사용

  - 데이터셋에 있는 모든 **ground truth box의 width, height 값**을 사용하여, k-means clustering 수행
  - box와 centroid의 IoU값이 클수록 겹치는 영역이 크기 때문에 거리가 가깝다는 의미

  $$
  d(box, centroid) = 1 - IOU(box, centroid)
  $$

- 

### 5. Direct location prediction

- YOLO와 anchor box를 함께 사용했을 때 문제점은 초기 iteration 시, 모델이 불안정하다는 것

  - 하지만 t_x,t_y와 같은 계수는 제한된 범위가 없기 때문에 anchor box는 이미지 내의 임의의 지점에 위치할 수 있음.
  - 이로 인해 최적화된 값을 찾기 까지 오랜 시간이 걸려 모델은 초기에 불안정

  $$
  x = (t_x * w_a) - x_a \\ y = (t_y * h_a) - y_a
  $$

- 이러한 문제를 해결하기 위해 YOLO의 방식을 사용하여 grid cell에 상대적인 위치 좌표를 예측하는 방법 선택

  - 예측하는 BB의 좌표는 0~1 사이의 값을 가짐
  - BB regression을 통해 얻은 t_x, t_y 값에 logistic regression 함수(σ)를 적용하여 0~1 사이의 값을 가지도록 조정
  - 예측하는 위치의 범위가 정해짐으로써 네트워크는 안정적으로 학습 진행

- Dimension clustering을 통해 최적의 prior를 선택하고, anchor box 중심부 좌표를 직접 예측함으로서 recall값이 5% 정도 향상

### 6. Fine-Grained Features

- YOLO v2는 최종적으로 13x13 크기의 feature map 출력
  -  feature map의 크기가 작은 경우 큰 객체를 예측하기 용이한 반면, 작은 객체는 예측하기 어려움

1. 이를 해결하기 위해 마지막 pooling을 수행하기 전에 feature map을 추출하여 26x26(x512) 크기의 feature map 추출

2. feature map의 channel은 유지하면서 4개로 분할한 후 결합(concat)하여 13x13(x2048)크기의 feature map 확보

   - **보다 작은 객체에 대한 정보를 함축**

   ![img](https://blog.kakaocdn.net/dn/48d9r/btqTrSVghra/vZWjLKoFtduGr6iyf59m51/img.png)

3. 13x13(x1024) feature map에 추가하여 13x13(x3072) 크기의 feature map 확보

4. 3x3 conv와 1x1 conv를 적용하여 **13x13(x125) 크기의 feature map** 추출

   - channel 수가 125인 이유는 각 grid cell별로 5개의 bounding box가 20개의 class score와 (confidence, x, y, w, h)를 예측하기 때문

   ![img](https://blog.kakaocdn.net/dn/bZmrxo/btqTlGas3xU/V2EMRiBMr7rKdKe4zNHXrk/img.png)

### 7. Multi-Scale Training

- 다양한 입력 이미지를 사용하여 네트워크 학습
  - 논문에서는 10 batch마다 입력 이미지의 크기를 랜덤하게 선택하여 학습
  - 모델은 이미지를 1/32배로 downsample시키기 때문에 입력 이미지 크기를 32배수 {320, 352, ..., 608} 중에서 선택
    - 320x320 크기의 이미지가 가장 작은 입력 이미지
- 네트워크는 다양한 크기의 이미지를 입력받을 수 있고, 속도와 정확도 사이의 trade-off를 제공
- 입력 이미지의 크기가 작은 경우 더 높은 FPS를 가지며, 입력 이미지의 크기가 큰 경우 더 높은 mAP 값을 가지게 됨

![img](https://blog.kakaocdn.net/dn/odVYc/btqTkgDaSf4/ZtMkQKYV7acSwJZoxofOC0/img.png)

## Faster

<hr>

