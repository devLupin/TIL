# FPN(Feature Pyramid Network)

<hr>

- 기존의 방식을 사용하면 모델의 추론 속도가 느려지고, 메모리를 지나치게 많이 사용
- 컴퓨팅 자원을 적게 차지하면서 다양한 크기의 객체를 인식하는 방법 제시



## Preview

<hr>

- 원본 이미지를 convolutional network에 입력하여 forward pass 수행

  - 각 stage마다 서로 다른 scale을 가지는 4개의 feature map 추출
  - 이를 **Bottom-up pathway**라고 함.

- 이후, **Top-down pathway**를 통해 각 feature map에 1x1 conv 연산을 적용하여 256 채널을 갖도록 조정하고 upsampling 수행

- 마지막으로, Lateral connections 과정을 통해 pyramid level 바로 아래 있는 feature map과 element-wise addtion 연산 수행

  - 얻어진 4개의 서로 다른 feature map에 3x3 conv 연산 적용

  ![img](https://blog.kakaocdn.net/dn/bkU5UW/btqUk0zKpRa/8NUxlWc9Bl2U6htCPXvkhk/img.png)



## What is Pyramid?

<hr>

- Convolutional network에서 얻을 수 있는 서로 다른 해상도의 feature map을 쌓아올린 형태

- level은 피라미드 각 층에 해당하는 feature map

  ![img](https://blog.kakaocdn.net/dn/AaYw6/btqUmaoQI9n/f0edQIJmCVbR3cAKaqrzdk/img.png)

- Convolutional network에서 더 얕은(입력층에 보다 가까운) feature map은 high resolution을 가지며, 가장자리, 곡선 등과 같은 low-level feature 보유

- 반대로 더 깊은 layer에서 얻을 수 있는 feature map은 low resolution을 가지며, 질감과 물체의 일부분 등 class를 추론할 수 있는 high-level feature를 가짐.

  ![img](https://blog.kakaocdn.net/dn/b9wSXt/btqUmaI6klz/MbwYgwR0kA4FQQwHOCCcmk/img.png)

- 피라미드의 각 level의 feature map을 일부 혹은 전부 사용하여 예측 수행



## 기존 방식

<hr>

### (a) Featurized image pyramid

- 입력 이미지 크기를 resize하여 다양한 scale의 이미지를 네트워크에 입력
- OverFeat 모델 학습 시 사용
- 객체를 포착하는데 좋은 결과를 보여주지만, 이미지 한 장을 독립적으로 모델에 입력하여 feature map을 생성
  - 추론 속도가 매우 느리며, 메모리를 매우 많이 사용

### (b) Single feature map

- 단일 scale의 입력 이미지를 네트워크에 입력하여 얻어진 feature map을 통해 object detection 수행
- YOLO v1 모델 학습 시 사용
- 학습 및 추론 속도가 매우 빠르지만, 성능이 떨어짐.

### (c) Pyramidal feature hierarchy

- 네트워크에서 미리 지정한 conv layer마다 feature map을 추출하여 detect

- SSD 모델 학습 시 사용

- multi-scale feature map을 사용하여 성능이 높지만, feature map 간 해상도 차이로 인해 학습하는 representation에서 차이인 semantic gap 발생

- 모델이 low-level에서 추출한 feature map에서 low-level feature까지 학습하면 representational capacity를 손상시켜 객체 인식률이 낮아짐.

  ![img](https://blog.kakaocdn.net/dn/Y7FpF/btqUnLou53n/QyGPoOBgLQpXliv4v6URdk/img.jpg)



## Feature Pyramid Network, FPN

<hr>

- 임의 크기의 single-scale 이미지를 convolutional network에 입력하여 다양한 scale의 feature map 출력
- 본 논문에서는 ResNet 사용
- **bottom-up pathway, top-down pathway, lateral connections**에 따라 진행

### Bottom-up pathway

- 이미지를 convolutional network에 입력하여 **forward pass하여 2배씩 작아지는** feature map 추출

  - 각 stage 마지막 layer의 output feature map 추출
  - 네트워크에는 같은 크기의 feature map을 출력하는 층이 많지만 논문에서는 모두 같은 stage에 속해있다고 정의

- 각 stage 별로 마지막 layer를 pyramid level로 지정

  - 더 깊은 layer일수록 더 강력한 feature 보유

- ResNet의 경우 각 stage 마지막 residual block의 output feature map을 활용하여 feature pyramid를 구성

  - 각 output을 {c2, c3, c4, c5}로 지정
    - 각각 conv2 ~ conv5의 output feature map임을 의미
    - 각각 {4, 8, 16, 32} stride를 가짐.
  - {c2, c3, c4, c5}은 각각 원본 이미지의 1/4, 1/8, 1/16, 1/32 크기를 가진 feature map
  - conv1은 너무 많은 메모리를 차지하여 피라미드에서 제외

  ![img](https://blog.kakaocdn.net/dn/bjyPWH/btqUtpfcWys/2JKOAbvrBFDi9AeNBZs1Yk/img.png)



### Top-down pathway and Lateral connections

1. 각 pyramid level에 있는 feature map을 2배로 upsampling하고 channel 수를 일치시키는 과정
   - 2배로 upsampling하면 바로 아래 level의 feature map과 크기가 같아짐.
   - **nearest neighbor upsampling** 방식 사용

![img](https://blog.kakaocdn.net/dn/wsui0/btqUuL9T7LI/18lKd5H2I0JKMyKY1Q180k/img.png)

2. 모든 pyramid level의 feature map에 1x1 conv연산을 적용하여 channel을 256으로 맞춤.

3. upsample된 feature map과 바로 아래 level의 feature map과 element-wise addition 연산을 하는 Lateral connections 과정 수행

4. 각각의 feature map에 3x3 conv 연산을 적용하여 얻은 feature map은 각각 {p2~p5}임.

   - 이는 {c2~c5} feature map의 크기와 동일
   - 가장 높은 level에 있는 feature map c2의 경우 1x1 conv 연산 후 그대로 출력하여 p2를 얻음.

   ![img](https://blog.kakaocdn.net/dn/k9LUD/btqUtXbErVx/1mZ793U5mBK5KgJPqsR9qK/img.png)

- 상기 과정을 통해 FPN은 single-scale 이미지를 입력하여 4개의 서로 다른 scale을 가진 feature map을 얻음.

  ![img](https://blog.kakaocdn.net/dn/ckoAbu/btqUvEisnBf/vfSQ81jV5fEkpp4e0u2tY0/img.png)

- 단일 크기의 이미지를 모델에 입력하므로 **(a) Featurized image pyramid**보다 빠르고 메모리 차지량도 적음.

- multi-scale feature map을 출력하기 때문에 **(b) Single feature map**보다 더 높은 detection 성능

- (Detection task) **고해상도 feature map은 low-level feature를 가지지만, 객체의 위치에 대한 정보를 상대적으로 정확하게 보존**

  - 저해상도 feature map에 비해 downsample된 수가 적기 때문

- **고해상도 feature map의 특징을 element-wise addition을 통해 저해상도 feature map에 전달하기 때문에 (c) Pyramidal feature hierarchy에 비해 작은 객체 감지 능력 더 우수**



## Training ResNet + Faster R-CNN with FPN

<hr>

- ResNet을 backbone network로 사용하는 Faster R-CNN에 FPN을 적용하여 학습

  ![img](https://blog.kakaocdn.net/dn/UDRzy/btqUBu683qh/VECU1zyeAbk5aj4Hg6HoRK/img.png)

### **1) Build Feature Pyramid by FPN**

1. ResNet 기반의 FPN에 이미지를 입력한 후 **Bottom-up pathway**을 거쳐 원본 이미지의 1/4, 1/8, 1/16, 1/32 크기에 해당하는 feature map {c2~c5} 출력

2. **Top-down pathway** 과정을 통해 1x1 conv 연산을 적용하여 모든 feature map의 channel 수를 256으로 맞춰주고 크기를 2배로 upsampling

3. **Lateral connections**을 통해 각 feature map을 바로 아래 pyramid level에 존재하는 feature map과 element-wise addtion 연산 수행

4. 3x3 conv 연산을 수행하여 {p2~p5} feature map 출력

   - **과정을 통해 얻은 feature pyramid {p2, p3, p4, p5}는 RPN와 RoI pooling 시 사용**

     

   - **Input** : single-scale image

   - **Process** : build feature pyramid 

   - **Output** : multi-scale feature map {p2, p3, p4, p5}

### **2) Class score and Bounding box by RPN**

1. 과정에서 얻은 feature map {p2~p5}를 **RPN(Region Proposal Network)**에 입력

   -  이 때 각 feature map을 그림과 같이 개별적으로 RPN에 입력하여 각각의 class score과 BB regressor를 출력

2. Non maximum suppression 알고리즘을 적용하여 class score가 높은 상위 1000개의 region proposal만을 출력

   

   - **Input** : multi-scale feature map {p2, p3, p4, p5}
   - **Process** : region proposal and Non maximum suppression
   - **Output** : 1000 region proposals

### **3) Max pooling by RoI pooling** 

- 1)에서 얻은 **multi-scale feature map {p2~p5}**와 2)를 통해 얻은 **1000개의 region proposals**를 사용하여 **RoI pooling** 수행

- Fast R-CNN은 single-scale feature map만을 사용한 반면, FPN을 적용한 Faster R-CNN은 multi-scale feature map을 사용하기 때문에 **region proposals를 어떤 scale의 feature map과 매칭**시킬지를 결정해야 함.

  - $$
    k = [k_0 + log_{2}(\sqrt{wh}/224)]
    $$

    - 위의 공식에 따라 region proposal을 k번째 feature map과 매칭

    - w, h는 RoI(=region proposal)의 width, height

    - k는 pyramid level의 index, k_0은 target level

      - 논문에서는 k_0 = 4

    - **RoI의 scale이 작아질수록 낮은 pyramid level, 즉 해상도가 높은 feature map에 할당하고 있음.**

      

  - **Input** : multi-scale feature map {p2~p5} and 1000 region proposals

  - **Process** : RoI pooling

  - **Output** : fixed sized feature maps

### 4) Train Faster R-CNN

- 3)을 통해 얻은 고정된 크기의 feature map을 Fast R-CNN에 입력한 후 전체 네트워크를 multi-task loss function을 통해 학습



## Detection

<hr>

- 실제 inference 시에는 Fast R-CNN의 마지막 예측에 Non maximum suppression을 적용하여 최적의 예측 결과만을 출력



## Conclusion

<hr>

- ResNet을 backbone network로 사용한 Faster R-CNN에 FPN을 결합시켰을 때, FPN을 사용하지 않았을 때보다 AP 값이 8% 이상 향상
- FPN은 end-to-end로 학습 가능
- 학습 및 테스트 시간이 일정하여 메모리 사용량이 적음.

