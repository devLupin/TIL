# **YOLO(You Only Look Once) V1**

<hr>

- 2-stage detector는 localization, classification을 수행하는 network 혹은 컴포넌트가 분리됨.
  - 각 task가 순차적으로 진행되는 것을 의미
  - 이 과정에서 병목 현상이 발생하여 detection 속도가 느려짐
- 1-stage detector는 하나의 통합된 네트워크가 동시에 진행



## **preview**

<hr>

- localization, classification을 하나의 문제로 정의하여 network가 동시에 두 task를 수행하도록 설계
- 이미지를 지정한 grid로 나누고, 각 grid cell이 한번에 BB와 class를 도출하도록 제작
- 각 grid 셀에서 얻은 정보를 feature map이 encode할 수 있도록 Convolution Network인 DarkNet 도입
- 자체적으로 정의한 regression loss를 통해 전체 모델 학습

![img](https://blog.kakaocdn.net/dn/sAQ55/btqRGp84eHj/fnQO3KiXWhQqtzK91249ok/img.jpg)



## **1. 1-stage detector**

<hr>

- 별도의 region proposals를 사용하지 않고, 전체 이미지를 입력하여 사용

- 전체 이미지를 SxS 크기의 grid로 분할

  - 객체의 중심이 특정 grid cell에 위치한다면 해당 grid cell은 그 객체를 detect하도록 할당(responsible for)됨.
  - **특정 grid cell이 할당되면 나머지 grid cell은 객체 예측에 참여할 수 없음을 의미**

- 각각의 grid cell은 B개의 BB와 해당 BB에 대한 confidence score 예측

  - confidence score는 해당 BB에 객체가 포함되어 있는지 여부, 얼마나 정확하게 ground truth box를 예측했는지 반영
  - 만약 0이라면 grid cell에 객체가 존재하지 않는다는 의미
  - grid cell에 객체가 존재하면 confidence score는 IoU값과 같아짐.

  $$
  confidence score = Pr(Object) * IoU(truth pred)
  $$

- 각각의 BB는 box의 좌표 정보(x,y,w,h)와 confidence score라는 5개의 예측값을 가짐.

  - (x, y)는 grid cell의 경계에 비례한 box의 중심 좌표
  - 높이, 너비 또한 grid cell에 비례한 값
  - x, y는 grid cell 내에 위치하므로, 0~1 사이의 값
  - w, h는 객체의 크기가 grid cell보다 클 수 있어 1 이상의 값을 가질 수도 있음.

- **하나의 BB는 하나의 객체만을 예측, confidence score가 가장높은 grid cell 하나를 BB 학습에 사용**

- **각 grid cell은 C개의 conditional class probabilities 예측**

  - 특정 grid cell에 객체가 존재한다고 가정했을 때, 특정 class i 일 조건부 확률값
  - BB 수와 상관없이 하나의 grid cell마다 하나의 조건부 확률 예측

- 위와 같은 과정을 통해 BB의 위치와 크기, class에 대한 정보 동시 예측

  - 논문에서는 S=7, B=2, C=20으로 설정
  - **이미지별 예측값의 크기는 7x7x(2x5+20)**



## **2. DarkNet**

<hr>

- 7x7x30에 맞는 feature map을 생성하기 위해 **DarkNet**이라는 독자적인 Convolutional Network 설계
- ImageNet 데이터셋을 통해 학습
- 이후 모델이 detection task를 수행할 수 있도록 4개의 Conv layer, 2개의 FC layer 추가
- classification task를 위해 학습시켰을 때는 224x224 크기의 이미지를 사용한 반면, detection task를 위한 학습 시에는 이미지의 크기를 키워 448x448 크기의 이미지 사용
  - detection task는 결이 고운(fine grained) 시각 정보를 필요로 하기 때문

![img](https://blog.kakaocdn.net/dn/ZtrsY/btqRVo2g9aw/IxoiCyCvyKmmx0uSW10L1k/img.png)



## **3. Loss Function**

<hr>

- regression시 사용되는 **Sum of Squared Error** 사용
- Localization loss, Confidence loss, Classification loss의 합으로 구성

![img](https://blog.kakaocdn.net/dn/w6AqO/btqRTS3Fn10/hbgeetINsVlw8onTi2YPp0/img.png)



## **4. Training YOLO v1**

<hr>

- DarkNet에 이미지를 입력하여 7x7x30 크기의 feature map을 loss function을 통해 학습시킴.

![img](https://blog.kakaocdn.net/dn/zzcHm/btqRCW02Lun/SKPtcmIpoYaYWIV8UAeWEK/img.png)



## **5. Detection**

<hr>

- 최종 예측 결과에 **Non Maximum Suppression** 알고리즘 적용
  - maP 값 2~3% 향상



## 6. 결론

<hr>

- base network의 경우 45fps, 경량화한 fast version의 network는 150fps의 결과를 보여 매우 빠른 detection 속도
- 실시간으로 0.0025 이하의 지연시간(latency)를 가지며 객체를 detect
- sliding window 방식이나 region proposal 기반의 모델과는 달리 전체 이미지를 인지하여 맥락 정보(contextual information)을 학습
  - 배경 영역을 객체로 인식하는 False Positive 오류 Fast R-CNN 모델 대비 감소
- 일반화 가능한 표현(representations)를 학습하여 새로운 도메인이나 예상치 못한 입력 이미지에 대해 상대적으로 좋은 성능
- 작은 객체를 제대로 탐지하지 못함.
- 각 grid cell의 BB는 하나의 객체만을 예측하기 때문에 같은 grid cell 내에 있는 여러 객체를 탐지하지 못함.





