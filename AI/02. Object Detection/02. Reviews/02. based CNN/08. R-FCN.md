# R-FCN(Region-based Fully Convolutional Networks)

<hr>



## 1. 제안 배경

<hr>

- 2-Stage detector는 서로 다른 task를 수행하는 두 sub-network 간 학습 속성 차에서 발생
- 이를 번역 불변성 딜레마(translate invariance Dilemma)라고 표현

- 번역 불변성 문제를 해결하기 위해 conv layer 사이에 RoI pooling 삽입
- 수 많은 RoI를 개별적으로 conv, fc layer에 입력해야 함.
- 학습, 추론 시 많은 시간 소요



## 2. 개요

<hr>

- backbone network, RPN으로 구성
  - backbone network는 특징 추출을 수행
    - ResNet-101 모델 사용
- 원본 이미지를 backbone network, RPN에 입력하여 **각각 채널을 가지는 Position-sensitive score map, ROI**를 얻음.
- 이를 활용하여 Position-sensitive RoI pooling을 수행하여 k x k 크기의 feature map 출력
- voting을 수행하여 C+1 크기의 특징 벡터를 얻고 이에 대한 loss 계산(softmax 함수 이용)
  - voting : feature map의 각 channel 별 요소의 평균값을 취함.

![img](https://blog.kakaocdn.net/dn/pYY4q/btqSGitusRA/I8bYIbO2uY9iFH99VINhk1/img.jpg)



## 3. 아이디어

<hr>

### Translation invariance Dilemma

- Translation invariance
  - 입력 값의 위치가 변해도 출력 값은 동일
  - 반대로, 입력 값의 위치가 변하면 출력값이 달라지는 경우 translation variance(=equivalence)
  - Image classification model은 translation invariance 속성 선호
    - 객체 내 위치가 바뀌더라도 동일한 객체로 인식해야 함.
  - Object detection model은 translation variance 속성 선호
    - 객체의 위치가 변화하면 이러한 변화를 잘 포착해야 함.
- 원본 이미지를 backbone network(feature 추출)에 입력하여 얻은 feature map은 translation invariance 속성을 띔.
- 그러나, 원본 이미지를 backbone network에 입력하여 얻은 feature map은 **위치 정보가 소실**된 상태
  - 객체에 대한 위치 정보가 부재한 feature map이 입력되어 부적절한 학습
- 두 네트워크 간에 충돌이 발생하는 경우를 의미
  - 이로 인해 mAP 값 하락
- ResNet+Faster R-CNN 모델은 두 conv layer 사이에 RoI pooling을 삽입해 region specific한 연산 추가
  - network가 서로 다른 위치에 있는 객체를 서로 다르게 인식함을 의미
  - RoI pooling layer 이후 conv layer는 translation variance 속성을 학습하는 것이 가능
- 그러나 ResNet+Faster R-CNN과 같은 방법은 성능은 높아지나, 모든 RoI를 개별적으로 conv, FC layer에 입력하기 때문에 학습 및 추론 속도가 느려짐.
  - R-FCN 모델은 RPN을 통해 추출한 RoI 간 연산을 공유하면서 객체의 위치 정보를 포함한 feature map 사용

![img](https://blog.kakaocdn.net/dn/5oSgi/btqSjBO4jzZ/D4eZVjjzEze4GmGgsnyOOK/img.png)

### Backbone Network

- pre-trained된 ResNet-101 사용
  - 모델의 average pooling layer와 FC layer를 제거
  - 오직 conv layer만으로 feature map을 연산하도록 학습시킴.
  - 마지막 feature map의 channel은 2048-D이며, 1x1 conv 연산을 적용하여 channel 수를 1024-D로 감소시킴.

### Position sensitive score maps & Position-sensitive RoI pooling

- RPN을 통해 얻은 각각의 RoI에 대하여 class별 위치 정보를 encode하기 위해 RoI를 k x k 구간의 grid로 나눔.
- RoI의 크기가 w x h인 경우 각 구간의 크기는 대략, w/k x h/k
- 논문에서는 k=3

![img](https://blog.kakaocdn.net/dn/d4MCxT/btqSdtRRcJT/2slOd2h2EHQDLfhze0DkoK/img.jpg)

- 앞서 얻은 feature map의 channel 수가 k^2(C+1)이 되도록 마지막 conv 연산을 적용하여 Position-sensitive score map 생성
  - C는 class수 의미
  - 배경을 포함하기 때문에 1을 더함.
- RoI를 k^2개의 구간으로 나눠 class 별 위치 정보에 해당하는 정보를 encode
- Position-sensitive score map, RoI를 활용하여 (i, j)번째 구간에서 오직 (i, j)번째 score map만 pooling
  - 이를 **Position-sensitive RoI pooling**이라고 함.

![img](https://blog.kakaocdn.net/dn/mzpHG/btqSduvKvUs/i23tAbJah0zRr806qohMAK/img.png)

- 각 class별로 w/k x h/k만큼의 RoI grid에 대해 average pooling
- 이를 통해 RoI별 크기가 k x k이며 channel 수가 (C+1)인 feature map 생성

![img](https://blog.kakaocdn.net/dn/yZtWs/btqSsQZpTPv/omPFMVYkv0KUCTxCLrD5WK/img.png)

- 이후 각 class별 k x k 크기의 feature map의 평균을 취함.
  - 이를 **voting**이라고 함.
- feature map의 평균을 통해 (C+1) 크기의 feature vector를 얻고 softmax 함수를 이용해 loss 계산
- position-sensitive RoI pooling + voting 수행 과정

![img](https://blog.kakaocdn.net/dn/b07A02/btqSxCNbNfw/gsldoL61HlGyAGewHUtVT0/img.jpg)

- BB regression 역시 k^2(C+1)-D feature map 외에도 4k^2-D feature map을 추가하여 수행

### Loss function

- cross-entropy loss + BB regression loss의 합으로 구성
- c*는 RoI의 ground truth label
- IoU 값을 기준으로 0.5 이상인 경우 c*=1, 그 외 0
- λ는 두 loss 사이의 가중치를 조절하는 balancing parameter
  - 논문에서는 1로 설정

$$
L(s, t_{x, y, w, h}) = L_{cls}(s_{c*}) + \lambda[c^* > 0]L_{reg}(t, t^*)
$$



## 4. Training

<hr>

![img](https://blog.kakaocdn.net/dn/c18nLI/btqSELvU8dZ/5s5CkN05JI9v3jhjljgYT0/img.png)

### 1) feature extraction by pre-trained ResNet-101

- 원본 이미지를 Resnet-101에 입력하여 feature map을 얻음.
  - **input : image**
  - **process : feature extration**
  - **output : feature map**

### 2) Position-sensitive score maps by conv layer

- feature map의 channel 수가 k^2(C+1)이 되도록 하는 conv layer에 입력하여 Position-sensitive score maps를 얻음.
  - 논문에서는 k=3, C=20으로 지정
  - BB regression도 동일한 방법
    - 다만, feature map을 channel이 4k^2이 되도록 하는 conv layer에 입력
    - RoI의 각 구간별 BB offset이 encode된 4k^2-D feature map을 얻음.
- **input : feature map**
- **process : 3x3(xk^2(C+1)) conv layer, 3x3(x4k^2) conv layer**
- **output : k^2(C+1)-d feature map(position-sensitive score map), 4k^2-d feature map**

### 3) Region proposal by RPN

- **Input : feature map from pre-trained ResNet-101**
- **Process : region proposal**
- **Output : RoIs**

### 4) Average pooling by Position-sensitive pooling

- 2)에서 얻은 featuremap들과 3)에서 얻은 RoI를 이용하여 Position-sensitive pooling 수행
- **Input : k^2(C+1)-d feature map(position-sensitive score map), 4k^2-d feature map and RoIs**
- **Process : position-sensitive pooling**
- **Output : k×k(×(C+1)) sized feature map, k×k(×4) sized feature map**

### 5) Voting

- 4)를 통해 얻은 feature map에 대해 각 channel의 요소들의 평균을 구하는 과정
- 입력된 feature map으로부터 BB regressor에 해당하는 길이가 4인 feature vector를 얻음.
- **Input : k×k(×(C+1)) sized feature map, k×k(×4) sized feature map**
- **Process : Voting**
- **Output : (C+1)-d sized feature vector, 4-d sized feature vector** 

### 6) Train R-FCN network by loss function

- 얻은 feature vector를 사용하여 cross-entropy, smooth L1 loss를 구한 후 backward pass를 통해 network 학습
- 실제 학습에서는 RPN, R-FCN을 번갈아가며 학습하는 4-step alternating training 방식 사용



## 5) Inference

<hr>

- detection 시에는 최종적으로 얻은 예측값에 **Non maximum suppression** 수행
  - nms threshold=0.7, IoU threshold=0.5로 설정

- class별로 객체의 위치 정보를 encode한 position-sensitive score & pooling을 통해 translation invariance dilemma를 효과적으로 해결

-  fully convolutional network이며, **오직 conv layer로만 구성**
- position-sensitive pooling 이후 학습 가능한 layer가 없기에, region-wise 연산량이 많지 않아 학습 및 추론 속도 굿