# Mask R-CNN

<hr>

- Fast R-CNN의 classification, localization(BB regression) branch에 mask branch 추가
- RPN 전에 FPN(feature pyramid network) 추가
- Image segmentation의 masking을 위해 RoI align 사용

- 프로세스

  1. 800 ~ 1024 사이즈로 이미지를 resize
  2. Backbone network(e.g, ResNet-101)의 인풋으로 들어가기 위해 1024 x 1024의 input_size를 맞춤
     - padding 이용
  3. ResNet-101을 통해 각 layer에서 feature map(C1 ~ C5) 생성
  4. FPN을 통해 이전에 생성된 feature map에서 P2 ~ P6 feature map 생성
  5. 최종 생성된 feature map에 각각 RPN을 적용하여 classification, BB regression 출력 값 도출
  6. 출력으로 얻은 BB regression 값을 원래 이미지로 projection 시켜 anchor box 생성
  7. NMS를 통해 생성된 anchor box 중 score가 가장 높은 anchor box를 제외하고 모두 삭제
  8. 크기가 다른 anchor box들을 RoI align을 통해 size를 맞춤.
  9. Fast R-CNN에서의 classification, BB regression branch와 더불어 mask branch에 anchor box 값을 통과시킴

  ![img](https://blog.kakaocdn.net/dn/c0pdEg/btqBL8vzmxg/1zkQAmbSKShCvdqXx8jXkk/img.png)



## 1. resize input image

<hr>

- Mask R-CNN에서 backbone으로 ResNet-101 사용

  - ResNet 네트워크는 이미지 input_size가 800~1024일 때 성능이 좋다고 알려짐.
  - VGG의 경우 224x224

- 이미지를 맞추는 데 **bilinear interpolation**을 사용하여 resize

  - 만약 upsampling 한다면 기존의 pixel value가 각각 양 끝으로 몰아짐.

    - e.g, 기존 pixel value P1 ~ P4
      - 나머지 값들을 bilinear interpolation으로 채움.

    ![img](https://blog.kakaocdn.net/dn/bsf2P5/btqBPYeHm3Z/aMt9hUpAVr57ZCPYrxv4B0/img.png)

    - 계산 방법

    ![img](https://blog.kakaocdn.net/dn/cPSvrn/btqBQnekM6R/0AbGEOE0zdw7AtjU1FckA0/img.png)

  - 기존의 이미지를 상기 방법으로 resize(800~1024)

  - 이후 input size인 1024x1024로 맞추기 위해 zero padding으로 나머지 값을 채움.



## 2. Backbone-ResNet101

<hr>

- structure

![img](https://blog.kakaocdn.net/dn/c9budm/btqBSOa9F71/Tf2pCxuju04Ke6wmovWyaK/img.png)



## 3. Feature Pyramid Network(FPN)

<hr>

- 이전의 Faster R-CNN에서는 backbone의 결과로 나온 1개의 feature map에서 roi를 생성하고 classification, BB regression 진행
  - 이렇게 최종 layer를 구성하면, 아주 중요한 feature만 남게 되고, 그 외의 feature들은 손실
  - 다양한 크기의 object 검출을 위해 여러 scale값으로 anchor를 생성하므로 비효율적임.
- 상기 문제 해결을 위해 FPN 사용
  - 마지막 layer의 feature map에서 이전의 중간 feature map들을 더하면서 이전 정보까지 유지
    - 여러 scale 값으로 anchor를 생성할 필요가 없음.
    - 모두 동일한 scale의 anchor 생성
- Upsampling을 통해 구현
  - 2배로 upsampling 진행 후, 이전 layer의 feature map을 1x1 Fully convolution 연산을 통해 filter 개수를 똑같이 맞춰준 후 더해 새로운 feature map 생성
  - 결과적으로 ResNet을 통해 C2~C5 feature map(F2~F5) 생성
    - 이 때, F5에서 maxpooling을 통해 F6 추가 생성
  - F2~F5는 RPN에 보내기 전, 3x3 convolution 연산을 거친다.
    - **upsampling, 이전 feature map을 더하면서 feature data가 조금 망가졌을 가능성 때문**
    - 반면, F6은 RPN에 그대로 전달



## 4. RPN

<hr>

- 각 feature map에서 1개의 scale의 anchor를 생성
  - 각 pyramid feature map마다 scale 1개 x ratio 3개 = 3개의 anchor 생성
- RPN을 통해 output으로 classification, BB regression(delta) 값이 추출
  - delta 값에 anchor 정보를 연산해서 **원래 이미지에 대응되는 anchor bounding box 좌표 값으로 변경**



## 5. Non-max-suppression

<hr>

- 원래 이미지에 anchor 좌표를 대응시킨 후에는 각각 normalized coordinate로 대응
  - FPN에서 이미 각 feature map 크기를 갖고 있어 통일을 위해 정규 좌표계로 이동
- 수천의 anchor box가 생성되면 NMS 알고리즘을 통해 anchor 개수 감소
  - anchor 중 classification score가 높은 anchor만을 채택
- NMS 알고리즘은 anchor BB를 score 순으로 정렬시킨 후 score가 높은 BB부터 다른 BB와 IOU 계산



## 6. RoI align

<hr>

- 기존 RoI pooling 방식은 소수점 좌표를 가지면 반올림하는 식으로 이동시킨 후 pooling
  - input image의 위치 정보가 왜곡되어 segmentation 문제 야기
- bilinear interpolation을 이용해서 위치 정보를 담는 RoI align 이용

![img](https://blog.kakaocdn.net/dn/rn1zn/btqBS6iJfmZ/hGQiZeuUGQNlSKhIuwdz8k/img.png)

