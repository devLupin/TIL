# **M2Det**(A single-Shot Object Detector based on Multi-Level Feature PyramidNetwork)

<hr>

- 본 눈문에서는 multi-scale feature map 생성을 위해 주로 사용되던 Feature Pyramid Network(FPN)의 한계에 대해 지적함.
  1. FPN은 classification task를 위해 설계된 backbone network로부터 feature map을 추출하는데, 이를 통해 구성된 feature pyramid는 **object detection task를 수행하기 위해 충분히 representative 하지 않음.**
  2. Feature pyramid의 각 level의 feature map은 주로 backbone network의 single-level layer로부터 구성되었고, 이로 인해 **객체의 외형에 따른 인식 성능 차이 발생**
     - 일반적으로 네트워크의 더 깊은 layer는 high-level feature는 classification task에 적합하고, 더 얕은 layer의 low-level feature는 localization task에 적합
     - 더 깊은 layer는 복잡한 외형 특징 포착하는데 유리하고, 더 얕은 layer는 단순한 외형을 파악하는데 유리함.
- 위의 문제를 해결하는 multi-scale, multi-level feature map을 사용하는 one-stage detector인 M2Det



## Preview

<hr>

- 서로 다른 크기와 외형의 복잡도를 가진 객체를 포착하기 위해 보다 효율적인 feature pyramid를 설계하는 네트워크인 MLFPN(Multi-Level Feature Pyramid Network)를 제시함.

  - 3개의 모듈로 구성됨.
    1. **FFM(Feature Fusion Module)**은 backbone network로부터 얕은 feature와 깊은 feature를 fuse(융합)하여 base feature 생성
    2. **TUM(Thinned U-shape Module)**은 서로 다른 크기를 가진 feature map 생성
    3. FFMv2는 base feature와 이전 TUM의 가장 큰 scale의 feature map을 fuse하고, 그 다음 TUM에 입력
    4. **SFAM(scale-wise Feature Aggregation Module)**은 multi-level, multi-scale feature를 scale-wise feature concatenation과 channel-wise attention 매커니즘을 통해 집계

- MLFPN, SSD를 결합하여 M2Det이라는 end-to-end one-stage detector 설계

  ![img](https://blog.kakaocdn.net/dn/zdTsl/btq1Gd4YtaV/LhiOQ8NbkmIjQo50dIlzkk/img.png)



## MLFPN(Multi-Level Feature Pyramid Network)

<hr>

- multi-level, multi-scale feature map을 구성하는 네트워크
- **FFM, TUM, SFAM**으로 구성

### 1) FFM(Feature Fusion Module)

- 네트워크에 있는 서로 다른 feature를 융합(fuse)하고, 이를 최종 multi-level feature pyramid를 설계하는 역할

- FFMv1

  - backbone network로부터 두 개의 서로 다른 scale을 가지는 feature map을 추출한 후 융합하여 **base feature map** 생성
    - 그림 (a)와 같이 각각의 feature map에 conv 연산을 적용하고, scale이 작은 feature map을 upsample시켜준 후 concat하여 하나의 feature map을 얻음.
      - 각각의 feature map은 얕고, 깊은 layer에서 추출되었기 때문에 풍분한 semantic 정보(high, low level features)를 MLFPN에 제공

- FFMv2

  - FFMv1이 생성한 base feature에 대해 conv 연산을 적용한 후 TUM의 가장 큰 scale의 feature map을 입력받아 concat한 후 **다음 TUM에 전달**(그림 b)
  - 입력으로 사용되는 두 Feature map의 scale이 같음.

  ![img](https://blog.kakaocdn.net/dn/crPYPB/btq1BxKBIm7/zmoMB2LmhL16WUIxkZ3Fg1/img.png)

### 2. TUM(Thinned U-shape Module)

- 입력받은 feature map에 대하여 multi-level feature map을 생성하는 역할 수행

- Encoder-Decoder 구조로 U자형 구조를 가짐.

  - **Encoder network**
    - 입력받은 feature map에 대해 3x3 conv(stride=2) 연산을 적용하여 **scale이 다른 다수의 feature map{E1 ~ E5} 출력**
  - **Decoder network**
    - Encoder network에서 출력한 다수의 feature map에 대해 더 높은 level(scale이 더 작은)에 대해 upsample한 후 바로 아래 level의 feature map과 element-wise하게 더해준 후 1x1 conv 연산 수행
    - 이를 통해, scale이 다른 다수의 feature map {D1~D6} 출력

  ![img](https://blog.kakaocdn.net/dn/w545P/btq1NuZz1Xw/ijC88eVWyytEVinjd5GB10/img.png)

- **MLFPN 내부에서 TUM은 FFM과 서로 교차하는 구조**

- FFMv1에서 얻은 base feature map을 첫 번째 TUM에 입력하여 feature map {D1~D6} 확보

  - 출력 중 가장 큰 feature map과 base feature map을 FFMv2를 통해 fuse한 후 두 번째 TUM에 입력
    - 이 과정을 반복
    - 논문에서는 총 8개의 TUM 사용

- 각 TUM의 Decoder network의 출력 결과는 입력으로 주어진 feature map의 level에 대한 multi-scale feature map에 해당

- 축적된 모든 TUM의 feature map은 multi-level, multi-scale feature 형성

- **초반의 TUM은 shallow-level feature, 중간의 TUM은 medium-level feature, 후반의 TUM은 deep-level feature 제공**

  ![img](https://blog.kakaocdn.net/dn/bj12le/btq1K39dYDO/1S5zaG52lSg3f2UOSORbWk/img.png)

  ### 3) SPAM(Scale-wise Feature Aggregation Module)

  - TUM들에 의해 생성된 multi-level, multi-scale feature를 **scale-wise feature concatenation, channel-wise attention** 매커니즘을 통해 집계하여 multi-level feature pyramid로 구성하는 역할

    ![img](https://blog.kakaocdn.net/dn/yBkvY/btq1KAfapcC/jKlugSbAsfFmrTIfFRUIi0/img.png)

  #### 1) Scale-wise feature concatenation

  - 각 TUM으로부터 생성된 multi-level feature map을 같은 scale 별로 concat하는 작업 수행

  - 각 TUM은 특정 level에 관련된 feature maps 출력

    - 논문에서는 8개의 TUM에서 6-scale의 feature map 출력

  - 최종적으로 서로 다른 level에 대한 정보를 함축한 8개의 feature map이 결합되어, 6개의 multi-level, multi-scale feature map 출력

    ![img](https://blog.kakaocdn.net/dn/bui2uX/btq1JznMCqq/VCz9vCMkOx1XwjKsR5z0O0/img.png)

  #### 2) Channel-wise attention

  - feature가 가장 많은 효율을 얻을 수 있는 channel에 집중(attention)하도록 설계하는 작업 수행

  - 해당 모듈은 Scale-wise feature concatenation 과정에서 출력한 feature map을 **SE(Squeeze Excitation)** block에 입력

    - SE block은 CNN에 부착하여 사용할 수 있는 블록

    - 연산량을 크게 늘리지 않으면서 정확도 향상

    - SE block step

      1. **Squeeze step** : 입력으로 들어온 HxWxC 크기의 feature map에 대하여 Global Average Pooling 수행

         - 각 channel을 하나의 숫자로 표현

      2. **Excitation step** : 앞서 얻은 1x1xC 크기의 feature map에 대하여 2개의 fc layer를 적용하여 channel별 상대적 중요도를 구함.

         - 두 번째 fc layer의 activation function을 sigmoid로 지정

         - 최종 output은 0~1 사이 값을 가져 channel별 중요도 파악 

      3. **Recalibration step** : 앞선 과정에서 구한 channel별 중요도와 원본 feature map을 channel별로 곱해줘 channel별로 중요도를 재보정(recalibrate)

      ![img](https://blog.kakaocdn.net/dn/ck0hN7/btq1JVxNcr2/rVHRhPSaG7gWYAU2Zrc2T0/img.png)

  - TUM이 출력한 multi-level, multi-scale feature map을 SE block에 입력하여 feature map의 channel별 중요도 재보정



## Training M2Det

<hr>

![img](https://blog.kakaocdn.net/dn/dOftut/btq1KddQK2u/YR1cOw4gq9EaYJ89k5rX61/img.png)

### 1) Extract two feature maps from backbone network

- backbone network로부터 서로 다른 level에서 서로 다른 scale을 가진 2개의 feature map 추출

- VGG or ResNet 사용

  

  - **Input** : image
  - **Process** : extract two feature maps 
  - **Output** : two feature maps within different scales

### 2) Generate Base feature map by FFMv1

- 1)에서 얻은 두 개의 feature map을 FFMv1 모듈을 통해 융합(fuse)하여 Base feature map 생성

  

  - **Input** : two feature maps within different scales
  - **Process** : fuse two feature maps
  - **Output** : Base feature map

### 3) Generate Multi-level, Multi-scale feature maps by jointly alternating FFMv2 and TUM

- 2)의 출력을 첫 번째 TUM에 입력하여 multi-level, multi-scale feature map을 얻음.

- 첫 번째 TUM에서 얻은 feature map 중 가장 scale이 큰 feature map과 base feature map을 FFMv2를 통해 융합(fuse)

- 융합된 feature map을 두 번째 TUM에 입력

- 논문에서는 TUM의 수를 8개로 설정했기 때문에 위의 과정을 반복하여 총 8개의 multi-level, multi-scale feature maps

  

  - **Input** : Base feature map
  - **Process** : Iterate through FFMv2s and TUMs
  - **Output** : 8 Multi-level, Multi-scale feature maps

### 4) Construct Final Feature pyramid by SFAM

- 3)의 출력을 Scale-wise feature concatenation 과정을 통해 scale 별로 feature map 결합

- 이후 결합된 각 feature map을 SE block에 입력하여 재보정된 6개의 feature map으로 구성된 Feature pyramid를 얻음.

  - 논문에서 feature pyramid는 6-scale

    

  - **Input** : 8 Multi-level, Multi-scale feature maps

  - **Process** : Scale-wise feature concatenation and Channel-wise attention

  - **Output** : Feature pyramid with 6 recalibrated feature maps 

### 5) Prediction by classification branch and BB regression branch

- Feature pyramid 각 level별 feature map을 두 개의 병렬로 구성된 conv layer에 입력하여 class score, BB regressor를 얻음.

  

  - **Input** : Feature pyramid with 6 recalibrated feature maps 
  - **Process** : classification and bbox regression 
  - **Output** : 6 class scores and bbox regressors



## Detection

<hr>

- 실 detection 시, 네트워크에서 예측한 BB에 대해 Soft NMS(Non-maximum suppression)를 적용하여 최종 prediction 출력



## Conclusion

<hr>

- M2Det은 MS COCO 데이터셋을 통해 실험했을 때, 15.8 FPS 속도 달성

- AP 값은 44.2%를 보임.

  ![img](https://blog.kakaocdn.net/dn/dVBCd1/btq1KcF2XSt/kHvg1y25BkklwzGxkFyVzk/img.png)

- multi-scale뿐 아니라 multi-level로 구성된 Feature pyramid 설계

- 객체의 외형(appearance)이 복잡한 상황을 처리하는데 유용하게 사용

- 객체의 크기, 외형의 복잡도를 잘 포착함.
- 비슷한 크기의 객체는 feature map에서 큰 activation value를 가짐.
- 객체의 외형도 복잡도가 높은 객체(예: 차보다는 사람)는 큰 activation value를 가짐.