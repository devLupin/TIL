# **바다나우 어텐션(Bahdanau Attention)**

<hr>



## 1. 바다나우 어텐션 함수(Bahdanau Attention Function)

<hr>

- 바다나우 어텐션 함수의 입/출력

**Attention(Q, K, V) = Attention Value**

```
t = 어텐션 메커니즘이 수행되는 디코더 셀의 현재 시점

Q = Query : t-1 시점의 디코더 셀에서의 은닉 상태
K = Keys : 모든 시점의 인코더 셀의 은닉 상태들
V = Values : 모든 시점의 인코더 셀의 은닉 상태들
```



## 2. 바다나우 어텐션(Bahdanau Attention)

<hr>

1. Attention score를 구함.

   - t-1 시점의 디코더 은닉상태 S_{i} 사용
   - S_{t-1}과 인코더의 i번째 은닉 상태의 어텐션 스코어 계산 방법

   $$
   score(s_{t-1},\ H) = W_{a}^{T}\ tanh(W_{b}s_{t-1}+W_{c}H)
   $$

   - 각각의 식과 구하는 과정

   $$
   tanh(W_{b}s_{t-1}+W_{c}H)
   $$

   ![img](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%982.PNG)

   ![img](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%983.PNG)
   $$
   e^{t} = W_{a}^{T}\ tanh(W_{b}s_{t-1}+W_{c}H)
   $$
   ![img](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%984.PNG)

2. 소프트맥스 함수를 통해 어텐션 분포를 구함.

   - 각각의 값은 어텐션 가중치(Attention Weight)

   ![img](https://wikidocs.net/images/page/73161/%EC%96%B4%ED%85%90%EC%85%98%EB%94%94%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B7%B0%EC%85%98.PNG)

3. 각 인코더의 어텐션 가중치와 은닉상태를 가중합하여 어텐션 값을 구함.

   - 이 값은 컨텍스트 벡터라고도 부름.

   ![img](https://wikidocs.net/images/page/73161/%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%B2%A1%ED%84%B0.PNG)

4. 컨텍스트 벡터로부터 디코더의 은닉상태를 구함.

   - 컨텍스트 벡터와 현재 시점의 입력인 단어의 임베딩 벡터를 concatenate하고 현재 시점의 새로운 입력으로 사용
   - t-1 시점으로부터 전달받은 은닉상태와 현재 시점의 새로운 입력으로부터 디코더의 은닉상태를 구함.
   - 추출된 디코더의 은닉상태는 출력층으로 전달되어 현재 시점의 예측값을 구함.

   ![img](https://wikidocs.net/images/page/73161/%EB%B0%94%EB%8B%A4%EB%82%98%EC%9A%B0%EC%96%B4%ED%85%90%EC%85%985.PNG)

   