# BLEU Score(Bilingual Evaluation Understudy Score)

<hr>

- 언어 모델의 성능 측정을 위한 평가 방법으로 펄플렉서티(perplexity, PPL)가 있음.
- 이를 기계 번역기에도 사용할 수는 있으나, 번역의 성능을 직접적으로 반영하는 수치로의 사용은 애매함.



## **1. BLEU(Bilingual Evaluation Understudy)**

- 기계 번역 결과와 사람이 직접 변역한 결과가 얼마나 유사한지 비교하여 번역에 대한 성능 측정
- 측정 기준은 n-gram
- BLEU benefits
  - 언어에 구애받지 않은 사용
  - 계산 속도 빠름.
- 높을 수록 성능이 더 좋음을 의미

### 1) 단어 개수 카운트로 측정(Unigram Precision)

- 가장 직관적인 성능 평가 방법은 ref 중 한 문장이라도 등장한 단어의 개수를 Ca에서 카운팅
  - Candidate를 Ca로, Reference를 Ref로 축약
- 이를 유니그램 정밀도(Unigram Precision)이라고 함.

$$
\text{Unigram Precision =}\frac{\text{Ref들 중에서 존재하는 Ca의 단어의 수}}{\text{Ca의 총 단어 수}} = \frac{\text{the number of Ca words(unigrams) which occur in any Ref}}{\text{the total number of words in the Ca}}
$$

### 2) 중복을 제거하여 보정(Modified Unigram Precision)

- 정밀도의 분자를 계산하기 위해 Ref와 매칭하여 카운트하는 과정에서 Ca의 유니그램이 이미 Ref에서 매칭된 적이 있었는지 고려해야 함.

- 우선, 유니그램이 하나의 Ref에서 최대 몇 번 등장했는지 카운트

  - 이 값이 기존의 단순 카운트한 값보다 작은 경우, 이 값을 최종 카운트 값으로 대체

  $$
  Count_{clip}\ =\ min(Count,\ Max
  $$

- 보정된 유니그램 정밀도(Modified Unigram Precision)

$$
\text{Modified Unigram Precision =}\frac{\text{Ca의 각 유니그램에 대해 }Count_{clip}\text{을 수행한 값의 총 합}}{\text{Ca의 총 유니그램 수}}=\frac{\sum_{unigram∈Candidate}\ Count_{clip}(unigram)}
{\sum_{unigram∈Candidate}\ Count(unigram)}
$$

### 3)  보정된 유니그램 정밀도 구현

```python
# 반드시 임포트
from collections import Counter
import numpy as np
from nltk import ngrams

# 단순 카운트 함수
def simple_count(tokens, n): # 토큰화 된 candidate 문장, n-gram에서의 n
    return Counter(ngrams(tokens, n)) #문장에서 n-gram을 카운트

candidate = "It is a guide to action which ensures that the military always obeys the commands of the party."
tokens = candidate.split() #단어 토큰화
result = simple_count(tokens, 1) #토큰화 된 문장, 유니그램의 개수를 구하고자 한다면 n=1
print(result)
"""
>>
Counter({('the',): 3, ('It',): 1, ('is',): 1, ('a',): 1, ('guide',): 1, ('to',): 1, ('action',): 1, ('which',): 1, ('ensures',): 1, ('that',): 1, ('military',): 1, ('always',): 1, ('obeys',): 1, ('commands',): 1, ('of',): 1, ('party.',): 1})
"""

candidate = 'the the the the the the the'
tokens = candidate.split() #단어 토큰화
result = simple_count(tokens, 1)
print(result)
"""
>>
Counter({('the',): 7})
"""

def count_clip(candidate, reference_list, n):
    cnt_ca = simple_count(candidate, n)
    # Ca 문장에서 n-gram 카운트
    temp = dict()

    for ref in reference_list: # 다수의 Ref 문장에 대해서 이하 반복
        cnt_ref = simple_count(ref, n)
        # Ref 문장에서 n-gram 카운트

        for n_gram in cnt_ref: # 모든 Ref에 대해서 비교하여 특정 n-gram이 하나의 Ref에 가장 많이 등장한 횟수를 저장
            if n_gram in temp:
                temp[n_gram] = max(cnt_ref[n_gram], temp[n_gram]) # max_ref_count
            else:
                temp[n_gram] = cnt_ref[n_gram]

    return {
        n_gram: min(cnt_ca.get(n_gram, 0), temp.get(n_gram, 0)) for n_gram in cnt_ca
        # count_clip=min(count, max_ref_count)
        # 위의 get은 찾고자 하는 n-gram이 없으면 0을 반환
     }

candidate = 'the the the the the the the'
references = [
    'the cat is on the mat',
    'there is a cat on the mat'
]
result = count_clip(candidate.split(),list(map(lambda ref: ref.split(), references)),1)
print(result)
"""
>>
{('the',): 2}
"""

# 보정된 정밀도 연산
def modified_precision(candidate, reference_list, n):
    clip = count_clip(candidate, reference_list, n) 
    total_clip = sum(clip.values()) # 분자

    ct = simple_count(candidate, n)
    total_ct = sum(ct.values()) #분모

    if total_ct==0: # n-gram의 n이 커졌을 때 분모가 0이 되는 것을 방지
      total_ct=1

    return (total_clip / total_ct) # 보정된 정밀도
    # count_clip의 합을 분자로 하고 단순 count의 합을 분모로 하면 보정된 정밀도
    
result=modified_precision(candidate.split(),list(map(lambda ref: ref.split(), references)),1) # 유니그램이므로 n=1
print(result)
"""
>>
0.2857142857142857 	# 2/7
"""
```

### 4) 순서를 고려하기 위한 n-gram

- 보정된 유니그램 정밀도는 유니그램의 순서를 고려하지 않음.

- 이를 위해 개별적인 유니그램/단어로써 카운트하는 유니그램 정밀도에서 다음에 등장한 단어까지 함께 고려하여 카운트하도록 유니그램 외에도 Bigram, Trigram, 4-gram 단위 등으로 계산한 정밀도. 즉, n-gram을 이용한 정밀도를 도입

- n-gram의 정밀도 식
  $$
  p_{n}=\frac{\sum_{n\text{-}gram∈Candidate}\ Count_{clip}(n\text{-}gram)}
  {\sum_{n\text{-}gram∈Candidate}\ Count(n\text{-}gram)}
  $$

- 

- BLEU 정밀도 식
  - 보정된 정밀도 n을 모두 조합하여 사용

$$
BLEU = exp(\sum_{n=1}^{N}w_{n}\ \text{log}\ p_{n})
\ \\
pn : 각\ gram의\ 보정된\ 정밀도\ \\ \ \\
N : n-gram에서\ n의\ 최대\ 숫자\ 보통은\ 4.(p1,p2,p3,p4를\ 사용한다는\ 것)\ \\ \ \\
wn : 각\ gram의\ 보정된\ 정밀도에\ 서로\ 다른\ 가중치를\ 줄\ 수\ 있음.\ 이\ 가중치의\ 합은\ 1. \ \\
$$

### **5) 짧은 문장 길이에 대한 패널티(Brevity Penalty)**

- 제대로 된 번역이 아님에도 문장의 길이가 짧다는 이유로 높은 점수를 받는 문제가 존재
- 브레버티 패널티(Brevity Penalty) : Ca가 Ref보다 문장의 길이가 짧은 경우에는 점수에 패널티
- 브레이브 패널티 BP를 적용한 최종 BLEU 식

$$
BLEU = BP × exp(\sum_{n=1}^{N}w_{n}\ \text{log}\ p_{n})
\\ \\
\
BP = \begin{cases}1&\text{if}\space c>r\\ e^{(1-r/c)}&\text{if}\space c \leq r \end{cases}
\ \\
c  : Candidate의\ 길이 \ \\
r : Candidate와\ 가장\ 길이\ 차이가\ 작은\ Reference의\ 길이
$$

```python
# r을 구하는 코드
def closest_ref_length(candidate, reference_list): # Ca 길이와 가장 근접한 Ref의 길이를 리턴하는 함수
    ca_len = len(candidate) # ca 길이
    ref_lens = (len(ref) for ref in reference_list) # Ref들의 길이
    closest_ref_len = min(ref_lens, key=lambda ref_len: (abs(ref_len - ca_len), ref_len))	# 길이 차이를 최소화하는 Ref 탐색
    return closest_ref_len
```

- 만약 Ca와 길이가 정확히 동일한 Ref가 있다면 길이 차이가 0인 최고 수준의 매치(best match length)
- 만약 서로 다른 길이의 Ref이지만 Ca와 길이 차이가 동일한 경우에는 더 작은 길이의 Ref 택

```python
# BP를 구하는 코드
def brevity_penalty(candidate, reference_list):
    ca_len = len(candidate)
    ref_len = closest_ref_length(candidate, reference_list)

    if ca_len > ref_len:
        return 1
    elif ca_len == 0 :
    # candidate가 비어있다면 BP = 0 → BLEU = 0.0
        return 0
    else:
        return np.exp(1 - ref_len/ca_len)
```

```python
# BLEU score calc
def bleu_score(candidate, reference_list, weights=[0.25, 0.25, 0.25, 0.25]): 	# 임의의 동일한 가중치
    bp = brevity_penalty(candidate, reference_list) # 브레버티 패널티, BP

    p_n = [modified_precision(candidate, reference_list, n=n) for n, _ in enumerate(weights,start=1)]    # p1, p2, p3, ..., pn
    score = np.sum([w_i * np.log(p_i) if p_i != 0 else 0 for w_i, p_i in zip(weights, p_n)])
    return bp * np.exp(score)
```



## 2. BLEU 측정 with NLTK

<hr>

```python
import nltk.translate.bleu_score as bleu


candidate = 'It is a guide to action which ensures that the military always obeys the commands of the party'
references = [
    'It is a guide to action that ensures that the military will forever heed Party commands',
    'It is the guiding principle which guarantees the military forces always being under the command of the Party',
    'It is the practical guide for the army always to heed the directions of the party'
]

# 이번 챕터에서 구현한 코드로 계산한 BLEU 점수
print(bleu_score(candidate.split(),list(map(lambda ref: ref.split(), references))))
# NLTK 패키지 구현되어져 있는 코드로 계산한 BLEU 점수
print(bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split()))
```

