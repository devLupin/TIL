# 합성곱 신경망(Convolution Neural Network, CNN)

<hr>

- 이미지 처리에 탁월한 성능을 보이는 신경망
- **합성곱층과(Convolution layer)**와 **풀링층(Pooling layer)**으로 구성

![img](https://wikidocs.net/images/page/64066/convpooling.PNG)

-  합성곱층 : CONV는 합성곱 연산을 의미하고, 합성곱 연산의 결과가 활성화 함수 ReLU를 지남.
- 이후 POOL(풀링 연산) 구간을 지남.



## 1. CNN의 필요성

<hr>

- 변환 전에 가지고 있던 공간적인 구조(spatial structure) 정보가 유실된 상태
- 공간적인 구조 정보라는 것은 거리가 가까운 어떤 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리는 값이 비슷하거나 등을 포함
- 이미지의 공간적인 구조 정보를 보존하면서 학습할 수 있는 방법이 필요해졌고, 이를 위해 사용하는 것이 합성곱 신경망



## 2. 채널(Channel)

<hr>

- 이미지는 **(높이, 너비, 채널)**이라는 3차원 텐서
- 높이는 이미지의 세로 방향 픽셀 수, 너비는 이미지의 가로 방향 픽셀 수, 채널은 색 성분을 의미
- ex) (28 × 28 × 1)의 크기를 가지는 3차원 텐서

![img](https://wikidocs.net/images/page/64066/conv2.png)

- 컬러 이미지는 적색(Red), 녹색(Green), 청색(Blue) 채널 수가 3개
- 채널은 때로는 깊이(depth)라고도 함. 이 경우 이미지는 **(높이, 너비, 깊이)**라는 3차원 텐서로 표현



## 3. 합성곱 연산(Convolution operation)

<hr>

- 합성곱층은 합성곱 연산을 통해서 **이미지의 특징을 추출**하는 역할

- **커널(kernel)** 또는 **필터(filter)**라는 n×m 크기의 행렬로 높이(height)×너비(width) 크기의 이미지를 처음부터 끝까지 겹치며 훑으면서 n×m크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 것

  - 이미지의 가장 왼쪽 위부터 가장 오른쪽까지 순차적
  - 커널(kernel)은 일반적으로 3 × 3 또는 5 × 5를 사용

- ex) 예에서 5 × 5 이미지에 3 × 3의 커널로 합성곱 연산을 하였을 때, 스트라이드가 1일 경우 ==> 3 x 3의 특성맵 확보

  1. (1×1) + (2×0) + (3×1) + (2×1) + (1×0) + (0×1) + (3×0) + (0×1) + (1×0) = 6

  ![img](https://wikidocs.net/images/page/64066/conv4.png)

  2. (2×1) + (3×0) + (4×1) + (1×1) + (0×0) + (1×1) + (0×0) + (1×1) + (1×0) = 9

  ![img](https://wikidocs.net/images/page/64066/conv5.png)

  3. (3×1) + (4×0) + (5×1) + (0×1) + (1×0) + (2×1) + (1×0) + (1×1) + (0×0) = 11

  ![img](https://wikidocs.net/images/page/64066/conv6.png)

  4. (2×1) + (1×0) + (0×1) + (3×1) + (0×0) + (1×1) + (1×0) + (4×1) + (1×0) = 10

  ![img](https://wikidocs.net/images/page/64066/conv7.png)

  9. 최종결과

  ![img](https://wikidocs.net/images/page/64066/conv8.png)

- 입력으로부터 커널을 사용하여 합성곱 연산을 통해 나온 결과를 **특성 맵(feature map)**
- 이동 범위를 **스트라이드(stride)** - 녹색 스퀘어



## 4. 패딩(Padding)

<hr>

- 합성곱 연산의 결과로 얻은 특성 맵은 입력보다 크기가 작아진다는 특징
- 합성곱 층을 여러개 쌓았다면 최종적으로 얻은 특성 맵은 초기 입력보다 매우 작아진 상태가 됨.
- **합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지**되도록 하고 싶다면 패딩(padding) 사용

- 패딩은 (합성곱 연산을 하기 전에) **입력의 가장자리에 지정된 개수의 폭만큼 행과 열을 추가**해주는 것
  - 주로 값을 0으로 채우는 제로 패딩(zero padding) 사용



## 5. Weight, Bias

<hr>

### 1. Weight of CNN

- CNN에서 가중치는 **커널 행렬의 원소**

- 이미지를 1차원 텐서인 벡터로 만들면, 3 × 3 = 9가 되므로 입력층은 9개의 뉴런을 지님

  - ex) 4개의 뉴런을 가지는 은닉층 추가

    - 9 × 4 = 36개의 가중치

      ![img](https://wikidocs.net/images/page/64066/conv11.png)

    - 2 × 2 커널, 스트라이드는 1

    ![img](https://wikidocs.net/images/page/64066/conv12.png)

![img](https://wikidocs.net/images/page/64066/conv13.png)

- 특성 맵을 얻기 위해서는 동일한 커널로 이미지 전체를 훑으며 합성곱 연산 진행
  - 사용되는 가중치는 w0~w3
  - 각 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아니라, 커널과 맵핑되는 픽셀만을 입력으로 사용
  - 다층 퍼셉트론을 사용할 때보다 훨씬 적은 수의 가중치를 사용하며 공간적 구조 정보를 보존

- 합성곱 연산을 통해 얻은 특성 맵은 비선형성 추가를 위해서 활성화 함수를 지나게 됨.
  - 주로 ReLu, ReLu 변형 사용

- 합성곱 층(Convolution Layer) :  합성곱 연산을 통해서 특성 맵을 얻고, 활성화 함수를 지나는 연산을 하는 합성곱 신경망의 은닉층

### 2. Bias of CNN

-  커널을 적용한 뒤에 더함.
- 편향은 하나의 값만 존재하며, 커널이 적용된 결과의 모든 원소에 더해짐.



## 6. Feature map 크기 계산 방법

<hr>

$$
Ih : 입력의 높이 \ \\
Iw : 입력의 너비 \ \\
Kh : 커널의 높이 \ \\
Kw : 커널의 너비 \ \\
S : 스트라이드 \ \\
Oh : 특성 맵의 높이 \ \\
Ow : 특성 맵의 너비
$$



- floor 함수는 소수점 이하를 버리는 역할, 패딩의 폭 P 일 때, **Feature map의 높이, 너비**

$$
O_{h} = floor(\frac{I_{h} - K_{h}}{S}+1)
$$

$$
O_{w} = floor(\frac{I_{w} - K_{w}}{S}+1)
$$



## 7. 3D 텐서의 합성곱 연산

<hr>

- 다수의 채널을 가진 입력 데이터를 가지고 합성곱 연산을 한다고 하면 커널의 채널 수도 입력의 채널 수만큼 존재해야 함.
- 채널 수가 같으므로 합성곱 연산을 채널마다 수행
- 그 결과를 모두 더하여 최종 특성 맵 확보
- ex) 3개의 채널을 가진 입력 데이터, 3개의 채널을 가진 커널의 합성곱 연산
  - 높이 3, 너비 3, 채널 3의 입력이 높이 2, 너비 2, 채널 3의 커널과 합성곱 연산을 하여 높이 2, 너비 2, 채널 1의 특성 맵을 얻는다는 의미

![img](https://wikidocs.net/images/page/64066/conv15.png)



## 8. 3D 텐서의 합성곱 연산 일반화

<hr>

$$
Ih : 입력의 높이 \ \\
Iw : 입력의 너비 \ \\
Kh : 커널의 높이 \ \\
Kw : 커널의 너비 \ \\
Oh : 특성 맵의 높이 \ \\
Ow : 특성 맵의 너비 \ \\
Ci : 입력 데이터의 채널
$$

- 3D 텐서의 합성곱 연산

![img](https://wikidocs.net/images/page/64066/conv16_final.png)

- 합성곱 연산에서 다수의 커널을 사용할 경우

  - **사용한 커널 수는 합성곱 연산의 결과로 나오는 특성 맵의 채널 수**
  - (가중치는 커널의 원소들이므로) 하나의 커널의 하나의 채널은 Ki x Ko 개의 매개변수
  - (입력 데이터와 채널 수가 동일 해야 하므로) 커널이 가지는 매개변수의 수는 Ki x Ko x Ci
  - 이러한 커널이 총 Co개

  $$
  가중치\ 매개변수의\ 총\ 수 : Ki × Ko × Ci × Co
  $$

  

![img](https://wikidocs.net/images/page/64066/conv17_final_final.PNG)



## 9. 풀링(Pooling)

<hr>

- 일반적으로 합성곱 층(합성곱 연산 + 활성화 함수) 이후 풀링 층을 추가함.

- 풀링 층은 **특성 맵을 다운샘플링하여 특성 맵의 크기를 줄이는 풀링 연산**이 이뤄짐.

- 커널과 스트라이드의 개념이 존재하지만, 학습해야할 가중치가 없으며 연산 후의 채널 수가 변하지 않음.

- 풀링 이후, 특성 맵의 크기가 줄어들어 특성 맵의 가중치 개수도 줄여줌.

  - 맥스 풀링 연산

    - Feature map이 절반 크기로 다운 샘플링
    - 커널과 겹치는 영역 안에서 최대 값을 추출하는 방식으로 다운 샘플링

    ![img](https://wikidocs.net/images/page/64066/maxpooling.PNG)

  - 평균 풀링

    - 평균값을 추출하는 연산