## 1. 1D 합성곱(2D Convolutions)

<hr>

- 각 단어가 벡터로 변환된 문장 행렬이 입력이 됨.
- n은 문장의 길이, k는 임베딩 벡터의 차원

![img](https://wikidocs.net/images/page/80437/sentence_matrix.PNG)

-  커널의 너비는 문장 행렬에서의 임베딩 벡터의 차원과 동일하게 설정
  - 너비 방향으로 움직일 곳이 없음.
- 커널은 신경망 관점에서는 가중치 행렬이므로 커널의 사이즈에 따라 학습하게 되는 파라미터 수가 다름.
- 자연어 처리 관점에서는 커널의 사이즈에 따라 참고하는 단어 묶음의 크기가 달라짐.



## 2. 맥스 풀링(Max -pooling)

<hr>

- 1D CNN에서도 합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층(대표적으로 맥스 풀링) 추가
  - 맥스 풀링 : 각 합성곱 연산으로부터 얻은 결과 벡터에서 가장 큰 값을 가진 스칼라 값을 뺌.



## 3. 신경망 설계

<hr>

- 합성곱 연산을 한 후, 얻은 벡터에 맥스 풀링을 진행하고, 이 값들을 전부 연결(concatenate)하여 하나의 벡터로 만듦.
- 1D CNN을 통해 문장으로부터 얻은 최종 특성 벡터로 뉴런이 2개인 출력층에 완전 연결(Dense lyaer 사용)