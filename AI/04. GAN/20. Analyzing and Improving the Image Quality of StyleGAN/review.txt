style gan은 물방울 모양의 특징(원래 이미지와 관련 없는)이 있었음.
- 고해상도로 갈 수록 물방울이 더 뚜렷해짐.

AdaIN operation은 각 특징들의 크기로부터 찾은 정보를 잠재적으로 파괴할 가능성이 있음.
- 물방울 모양의 특징이 G가 instance norm을 지나 신호 강도 정보를 의도적으로 숨긴 결과라고 가정
- G에서의 norm step을 제거했더니 물방울 모양의 특징이 완전히 제거됨.

v1에서는 AdaIN을 사용해서 일반화와 모듈화를 평균과 표준편차를 모두 사용하였지만, 실험 결과 표준편차에서만 사용해도 전혀 무관했음.

스타일 모듈레이션은 특정 피처맵에서 10배 가까이 증폭하여, 다음 레이어의 오작동 유발
- 들어오는 피처맵의 예상 통계를 기준으로 각 입력 피처맵을 조정
   - conv 가중치를 조정하여 구현

styleGAN v2에서는 랜덤변수가 unit standard deviation으로부터 온 분포(+ i.i.d)라고 가정
그 다음 norm에서는 이전의 공분산 결과를 저장하는 것을 목표로 함
  - 몇 개의 가중치 텐서 파라미터 재설정

활성화 함수를 고려하지 않기 위해 신호 분산 유지

G의 부드러움은 이미지의 퀄리티와 상관관계를 보임.

[Lazy regularization]
낮은 퀄리티 이미지는 작은 잠재 공간 region으로 압착됨.
왜곡의 누적은 훈련 프로세스를 손상시키고, 최종 이미지 품질이 저하됨.
    - 정규화 텀이 주 손실 함수보다 더 적은 계산
    - 이는 계산 비용과 메모리 사용량 크게 감소

[Path length regularization]
W의 고정 크기 단계는 이미지에서 0이 아닌 고정 크기 변경을 초래
 - 이미지 공간에서 임의의 방향으로 들어가서 해당하는 w 기울기 관찰
    - 기울기는 w 또는 이미지 공간 방향에 관계없이 동일한 길이에 가까워야 함.
G의 맵핑은 야코비안 매트릭으로부터 캡처
  - 야코비안이 직교할 때 최적의 성능
    - 길이를 보존
  - 명시적 계산 방지를 위해 표준 역전파 사용
보다 안정적이고 일관되게 작동하는 모델로 구성되어 아키텍처 탐색이 더 쉬워짐.
이미지 당 PPL 스코어의 분포가 더 타이트 해짐.

[Etc.]

- GAN 모델과 같은 비지도학습 모델의 성능 평가를 위해 인셉션 스코어, FID를 일반적으로 사용함.
- 해당 모델에서는 Perceptual Path Length(PPL) metric을 추가 도입하여 검증
   - PPL : 두 개의 임의 입력 간 보간 시 연속 이미지(VGG 임베딩) 간의 차이를 측정하는 기법