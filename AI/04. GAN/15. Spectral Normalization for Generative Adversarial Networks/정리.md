- - $$
    수식
    				
    					
    				
    				
    						
    				
    			
    				$$
    					
    				
    				
    				# **Spectral Normalization**
    
    <hr>
    
    - Lipschitz constant만이 튜닝해야할 hyper-parameter이고 **다른 hyper-parameter는 튜닝이 필요가 없음**
    - **구현이 간단**하고 **계산량이 적음**
    
    
    
    ## Introduction
    
    - high dimensional space에 존재하는 D는 때로는 정확하지 않은 density ratio estimation
    - GAN의 학습 방법은 unstable
      - D의 성능을 보장할 수 없고 GAN의 성능 역시 보장할 수가 없음.
    - [Towards Principled Methods for Training Generative Adversarial Networks](https://arxiv.org/abs/1701.04862)에 따르면 qdata와 PG의 support가 조금도 겹치지 않게 되면 D가 두 분포를 아주 완벽하게 구분할 수 있어 G가 학습을 할 수 없음.
      - G가 D를 도저히 속일 수 없음.
    
    
    
    ## Method
    
    - Notion
      $$
      f(x, \theta) = W^{L+1}a_L(W^L(a_{L-1}(W^{L-1}(...a_1(W^1(x)...))) \tag{1}
      \ \\
      \ \\
      \ \\
      f = discriminator\ (가장\ 마지막\ 확률을\ 반환해주는\ activation\ function의\ 직전\ layer까지)
      \ \\
      WL = L번째\ layer의\ weight\ (learning\ parameter) 
      \ \\
      aL = L번째\ activation\ function\ (ReLU,\ tanh\ ...)
      \ \\
      x = discriminator의\ input
      \ \\
      θ={W1,...,WL,WL+1}
      $$
    
      - qdata : 데이터의 분포
      - pG : 적대적 min-max 최적화를 통해 학습되는 G 분포
    
    - 완전한 D
    
      - activation function A를 붙여 x가 qdata에서 sample 된 확률을 반환
    
      $$
      D(x, \theta) = A(f(x, \theta)) \tag{2}
      $$
    
    - optimal해진 D인 D∗G는 fixed generator G에 대해 아래와 같은 density ratio estimation이 가능
    
      - optimal D에 대해 G를 학습하는 것을 가정
        $$
        D^*_G(x) = \frac{q_{data}(x)}{q_{data}(x) + P_G(x)} = sigmoid(f^*(x)), where f^*(x) = \log(q_{data}(x)) - \log(P_G(x)) \tag{3}
        $$
    
    - 최적화 D*의 허점
    
      - f∗(x) **의 derivate 값에 제한이 없고(Unbounded) 심지어 계산이 불가능 할 때도 있음**
        $$
        \bigtriangledown_x f^*(x) = {\partial{f^*(x)}\over\partial{x}} = \frac{1}{q_{data}(x)} \bigtriangledown_x q_{data}(x) - \frac{1}{P_G(x)} \bigtriangledown_x P_G(x) \tag{4}
        $$
    
    - **weight normalization** 방식을 통해 **D의 Lipschitz constant에 상한선 K를** 만들어 D를 stable하게 만들고자 함.
    
      - 이를 반영한 D의 objective function
    
        - f는 식(2)
    
      - **f의 Lipschitz constant가 K이하인 f 중에 V(G,D)를 maximize하는 f를 채택**
        $$
        f = \arg\max_{\lVert f \rVert \leq K} V(D, G) \tag{5}
        $$
        xxxxxxxxxx f = \arg\max_{\lVert f \rVert \leq K} V(D, G) \tag{5}
    				$$
    					
    				
    				
    					
    						f = \arg\max_{\lVert f \rVert \leq K} V(D, G) \tag{5}
    $$