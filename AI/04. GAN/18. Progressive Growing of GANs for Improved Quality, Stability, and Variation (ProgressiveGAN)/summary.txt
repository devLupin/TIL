<기초 연구>
PixelCNN(Autoregressive model), VAE, GAN은 강점과 약점을 지님
- PixelCNN의 경우, 검증 속도가 느리고, 잠재적 표현을 지니지 않음.
- VAE는 학습이 쉬우나, 모델의 제약 때문에 blurry한 결과를 생성함
- GAN은 작은 해상도, 제한적인 변형, 학습 불안정

<배경>
- 고해상도에서는 훈련 이미지와 생성된 이미지가 더욱 쉽게 구별되기에 기울기가 증폭
- 또한, 메모리 제약 때문에 더 작은 미니배치를 사용해야함.
   - 이는 훈련 안정성을 더 떨어뜨림.

<Progressive GAN>
- G, D에 점진적으로 층을 추가
   - 생성된 이미지의 공간 해상도 증가
- 처음 4x4에서 8x8, ...., 1024x1024로 공간 해상도 증가
   - D는 역순
- 고해상도의 합성의 안정화, 학습 속도 증가
- 다른 공간 해상도에서 동작하는 여러 D 사용

<변화 증가>
1. 미니배치를 통해 각 공간 위치의 특징 표준편차 계산
2. 모든 특징과 공간 위치를 하나의 값으로 만들기 위해 추정
3. 값을 복제하고 모든 공간 위치와 미니 배치를 통해 연결하여 하나의 추가 (상수) 기능 맵 생성
    - 이 레이어는 D의 어디에나 삽입가능하나, 실험 결과 맨 끝에 삽입하는게 베스트

<G, D 일반화>
1. 동일화된 학습률
  - N(0, 1) 초기화, 명시적으로 실행시간에 가중치 설정
    - RMSProp, Adam 등은 표준편차 추정을 통해 기울기 업데이트 일반화를 진행
    - 독립적인 파라미터 스케일 업데이트임.
    - 일부 매개 변수는 다른 매개 변수보다 더 큰 동적 범위를 가지며 조정하는 데 더 오래 걸림.
  - 학습 속도는 모든 가중치에 대해 동일
2. G에서의 픽셀별 특징벡터 일반화
  - G, D 경쟁에서 크기 제어가 벗어나는 것을 방지
  - local response normalization 사용
  - 신호 크기의 상승을 매우 효과적으로 방지

<MULTI-SCALE STATISTICAL SIMILARITY>
- 생성된 'Laplacian pyramid 표현으로부터 그려진 지역이미지 패치의 분포와 타겟 이미지 사이의 통계적 유사도를 고려
   - single Laplacian pyramid level은 특정 공간 주파수 대역
- 16x16 픽셀 해상도부터 시작
- 피라마드는 전체 해상도에 도달할 때까지 두배가 됨.
- 각 연속 레벨 차이를 이전 레벨의 업 샘플링된 버전으로 인코딩
- sliced Wasserstein distance(SWD)를 계산
  - EM distance의 근사를 랜덤하게 계산
    - EM distance는 결합확률 분포에서 x, y의 거리 기댓값을 가장 작게 추정한 값
- 작은 SWD는 패치 분포들의 유사도
- 평균은 해당 공간 해상도에서의 외관과 표준편차의 유사도
- 적은 해상도에서 추출된 패치 셋들 사이의 거리는 큰 스케일의 이미지 구조에서의 유사도로써 표기
   - 최고 수준의 패치는 가장자리 선명도 및 노이즈와 같은 픽셀 수준 속성에 대한 정보 인코딩