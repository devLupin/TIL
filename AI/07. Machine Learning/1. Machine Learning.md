# **머신러닝(Machine Learning, ML)**

<hr>

## 1. ML 모델의 평가

<hr>

- 일반적으로 훈련용, 검증용, 테스트용으로 분리
- 검증용 데이터는 모델의 성능을 조정하기 위한 용도(과적합 판단, 하이퍼파라미터의 조정)
- 하이퍼파라미터 : 값에 따라서 모델의 성능에 영향을 주는 매개변수
- 가중치와 편향은 학습을 통해 바꾼다.
- 학습과정
  - 학습 데이터를 통해 훈련
  - 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 튜닝
  - 검증이 끝났다면 테스트 데이터로 모델을 평가

![img](https://wikidocs.net/images/page/24987/%EB%8D%B0%EC%9D%B4%ED%84%B0.PNG)



## 2. 분류(Classification)와 회귀(Regression)

<hr>

- 선형 회귀를 통해 회귀 문제에 대해서 학습하고, 로지스틱 회귀를 통해 분류 문제를 학습
- 분류는 이진 분류(Binary Classification)과 다중 클래스 분류(Multi-Class Classification), 다중 레이블 분류(Multi-lable Classification)로 나뉨.
- 이진 분류 문제(Binary Classification)
  - 주어진 입력에 대해서 둘 중 하나의 답을 정하는 문제
- 다중 클래스 분류(Multi-class Classification)
  - 주어진 입력에 대해서 두 개 이상의 정해진 선택지 중 답을 정하는 문제 (ex. 5지선다형)
- 회귀 문제(Regression)
  - 연속된 값을 결과로 가짐.
  - e.g) 시계열 데이터를 이용한 추가 예측, 생산량 예측, 지수 예측 등



## 3.  머신러닝의  종류

<hr>

- 지도 학습(Supervised Learning), 비지도 학습(Unsupervised Learning), 강화 학습(Reinforcement Learning) 으로 나뉨.

- 지도학습

  - 레이블[label, y, 실제값]이라는 정답과 함께 학습

  - 기계는 예측값과 실제값의 차이인 오차를 줄이는 방식으로 학습

  - 예측값은 아래와 같이 표기함.
    $$
    \hat{y}
    $$

- 비지도 학습

  - 레이블 없이 학습
  - e.g) 토픽 모델링의 LDA, Word2Vec



## 4. 샘플(Sample)과 특성(Feature)

<hr>

- 대부분의 머신 러닝 문제는 1개 이상의 독립 변수 x를 가지고 종속 변수 y를 예측하는 문제
- 인공 신경망 모델은 독립 변수, 종속 변수, 가중치, 편향 등을 행렬 연산을 통해 연산하는 경우가 많음.
- 독립 변수 x의 행렬을 X라고 했을 때, 독립 변수의 개수 n, 데이터의 개수 m인 행렬 X는 아래와 같음.
  - 머신러닝에서 하나의 데이터, 하나의 행을 샘플(sample)이라고 함.
  - 종속 변수 y를 예측하기 위한 각각의 독립 변수 x를 특성(Feature)이라고 함.

![img](https://wikidocs.net/images/page/35821/n_x_m.PNG)



## 5.  혼동행렬(Confusion Matrix)

<hr>

- 머신 러닝에서 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)
- 정확도의 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주기 위해 사용

![image-20210209185559363](C:\Users\devLupin\AppData\Roaming\Typora\typora-user-images\image-20210209185559363.png)

- TP(True Positive), TN(True Negative), FP(False Postivie), FN(False Negative)
- True는 정답을 맞춘 경우고 False는 정답을 맞추지 못한 경우, Positive와 Negative는 각각 제시했던 정답
- ex) TN은 음성(Negative)이라고 대답하였는데 실제로 음성이라서 정답을 맞춘 경우



### 1)  정밀도(Precision)

- 양성이라고 대답한 전체 케이스에 대한 TP의 비율

$$
정밀도 = \frac{TP}{TP + FP}
$$

### 2) 재현률(Recall)

- 실제값이 양성인 데이터의 전체 개수에 대해서 TP의 비율
- 양성인 데이터 중에서 얼마나 양성인지를 예측(재현)했는지

$$
재현률 = \frac{TP}{TP + FN}
$$



## 6. 과적합(Overfitting)과 과소 적합(Underfitting)

<hr>

- 과적합

  - 훈련 데이터를 과하게 학습한 경우
  - 훈련 데이터에 대해서 과하게 학습하면 테스트 데이터나 실제 서비스에서의 데이터는 정확도가 좋지 않은 현상이 발생할 수 있음.
  - 과적합 상황에서 발생할 수 있는 훈련 횟수에 따른 훈련 데이터의 오차와 테스트 데이터의 오차 변화(그래프 참조)
    - X축의 epoch(에폭) : 전체 훈련 데이터에 대한 훈련 횟수

  ![img](https://wikidocs.net/images/page/32012/%EC%8A%A4%ED%8C%B8_%EB%A9%94%EC%9D%BC_%EC%98%A4%EC%B0%A8.png)

- 과소 적합
  - 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태
  - 훈련 데이터에 대해서도 보통 정확도가 낮음.